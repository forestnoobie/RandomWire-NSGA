{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayCode(n): \n",
    "  \n",
    "    # Right Shift the number \n",
    "    # by 1 taking xor with  \n",
    "    # original number \n",
    "    grayval = n ^ (n >> 1) \n",
    "    \n",
    "    return int(bin(grayval)[2:] )\n",
    "\n",
    "def graydecode(binary):\n",
    "    \n",
    "    # binary -> decimal\n",
    "    \n",
    "\n",
    "    binary1 = binary\n",
    "    decimal, i, n = 0, 0, 0\n",
    "    while(binary != 0): \n",
    "        dec = binary % 10\n",
    "        decimal = decimal + dec * pow(2, i) \n",
    "        binary = binary//10\n",
    "        i += 1\n",
    "    \n",
    "    # Taking xor until \n",
    "    # n becomes zero \n",
    "    inv = 0\n",
    "    while(decimal): \n",
    "        inv = inv ^ decimal; \n",
    "        decimal = decimal >> 1;\n",
    "\n",
    "    return inv \n",
    "\n",
    "def num2gray(n,gray_len):\n",
    "    gy = str(grayCode(n))\n",
    "    \n",
    "    if len(gy) < gray_len:\n",
    "        gy = '0'* (gray_len-len(gy)) + gy\n",
    "        \n",
    "    return gy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'0'*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grayCode(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graydecode(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gray Code Size 정하기\n",
    "* 100개 몇 자리 수가 필요한지 알아야 고정된 크기의 individual 생산 가능\n",
    "\n",
    "1. num_graph -> 필요한 자리수 추출\n",
    "2. 필요한 자리수를 설정\n",
    "3. 자리수 보다 적으면 앞에 0 붙여 주기\n",
    "4. string 형으로 해야 관리가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_graph = 100\n",
    "gray_len = len(str(grayCode(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000011'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num2gray(2,gray_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gray Code Crossover\n",
    "* individual를 gray code로 구성\n",
    "* 각 구획 별로 Crossover 실시 // 일정 확률 이상 (0.7) 일 때만 섞기 독립적으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "try:\n",
    "    from collections.abc import Sequence\n",
    "except ImportError:\n",
    "    from collections import Sequence\n",
    "\n",
    "from itertools import repeat\n",
    "\n",
    "def cxOnePoint(ind1, ind2):\n",
    "    \"\"\"Executes a one point crossover on the input :term:`sequence` individuals.\n",
    "    The two individuals are modified in place. The resulting individuals will\n",
    "    respectively have the length of the other.\n",
    "    :param ind1: The first individual participating in the crossover.\n",
    "    :param ind2: The second individual participating in the crossover.\n",
    "    :returns: A tuple of two individuals.\n",
    "    This function uses the :func:`~random.randint` function from the\n",
    "    python base :mod:`random` module.\n",
    "    \"\"\"\n",
    "    size = min(len(ind1), len(ind2))\n",
    "    cxpoint = random.randint(1, size - 1)\n",
    "    ind1[cxpoint:], ind2[cxpoint:] = ind2[cxpoint:], ind1[cxpoint:]\n",
    "\n",
    "    return ind1, ind2\n",
    "\n",
    "\n",
    "def cxgray(ind1,ind2,num_graph):\n",
    "    \n",
    "    gray_len = len(str(grayCode(num_graph)))\n",
    "    \n",
    "    ## gray_len : 한 개 gray code의 길이, 전체 //3 \n",
    "    new_ind1 = []\n",
    "    new_ind2 = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        temp_ind1 = ind1[gray_len*i:gray_len*(i+1)]\n",
    "        temp_ind2 = ind2[gray_len*i:gray_len*(i+1)]\n",
    "        print(temp_ind1)\n",
    "        if random.random() < 0.7 :\n",
    "            x1,x2 = cxOnePoint(temp_ind1,temp_ind2)\n",
    "            new_ind1.extend(x1)\n",
    "            new_ind2.extend(x2)\n",
    "        else:\n",
    "            new_ind1.extend(temp_ind1)\n",
    "            new_ind2.extend(temp_ind2)\n",
    "    \n",
    "    return new_ind1, new_ind2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gray Code 와 기존 차이점\n",
    "* Cross over 함수가 다름!\n",
    "* individual를 읽고 쓸 때 encode decode를 해줘야 / individual의 크기\n",
    "* hyperparameter에 graycode 유무로 넣어주기\n",
    "* 만약 graycode값이 100을 초과하면 값 랜덤으로 바꾸기? -. 100으로 넣기? // evaluation 전에 항상 확인하기! --> 여기 문제에 봉착, 기존에 있는 요소를 어떻게 대체할 것 인가 --> del 이용해주자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7318716656333025"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from easydict import EasyDict\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "from deap import tools\n",
    "from collections import OrderedDict\n",
    "from pprint import pprint\n",
    "import json\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from utils_kyy.utils_graph import make_random_graph\n",
    "from utils_kyy.create_toolbox import create_toolbox_for_NSGA_RWNN\n",
    "from utils_kyy.create_toolbox import evaluate\n",
    "from utils_kyy.utils_graycode import *\n",
    "\n",
    "\n",
    "class rwns_train:\n",
    "    def __init__(self, json_file):\n",
    "        self.root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "        #self.root = os.getcwd()\n",
    "        self.param_dir = os.path.join(self.root + '/parameters/', json_file)\n",
    "        f = open(self.param_dir)\n",
    "        params = json.load(f)\n",
    "        pprint(params)\n",
    "        self.name = params['NAME']\n",
    "        self.log_dir = os.path.join(self.root, 'log')\n",
    "        self.model_dir = os.path.join(self.root +'/saved_models/', self.name)\n",
    "        \n",
    "        \n",
    "        # create directory\n",
    "        if not (os.path.isdir(self.model_dir)):\n",
    "            os.makedirs(self.model_dir)\n",
    "        if not (os.path.isdir(self.log_dir)):\n",
    "            os.makedirs(self.log_dir)\n",
    "\n",
    "\n",
    "        ## toolbox params\n",
    "        self.args_train = EasyDict(params['ARGS_TRAIN'])\n",
    "        self.data_path = params['DATA_PATH']\n",
    "        self.run_code = params['RUN_CODE']\n",
    "        self.stage_pool_path = '../graph_pool' + '/' + self.run_code + '/'\n",
    "        self.log_path = '../logs/' + self.run_code + '/'\n",
    "        self.num_graph = params['NUM_GRAPH']\n",
    "        self.toolbox = None\n",
    "\n",
    "        ## GA params\n",
    "        self.pop_size = params['POP_SIZE']\n",
    "        self.ngen = params['NGEN']\n",
    "        self.cxpb = params['CXPB']\n",
    "        self.mutpb = params['MUTPB']\n",
    "\n",
    "        ## logs\n",
    "        log = OrderedDict()\n",
    "\n",
    "        log['hp'] = self.args_train\n",
    "        self.log = log\n",
    "        self.train_log = None \n",
    "        \n",
    "        \n",
    "        \n",
    "    ## tool box and make graph\n",
    "    def create_toolbox(self):\n",
    "        self.stage_pool_path = '../graph_pool' + '/' + self.run_code + '/'\n",
    "        self.log_path = '../logs/' + self.run_code + '_' + self.name + '/'\n",
    "\n",
    "        if not os.path.exists(self.stage_pool_path): os.makedirs(self.stage_pool_path)\n",
    "        if not os.path.isdir(self.log_path): os.makedirs(self.log_path)\n",
    "        self.log_file_name = self.log_path + 'logging.log'\n",
    "        self.train_log_file_name = self.log_path + 'train_logging.log'\n",
    "\n",
    "        logging.basicConfig(filename=self.log_file_name, level=logging.INFO)\n",
    "        logging.info('Start to write log.')\n",
    "\n",
    "        # num_graph = 100\n",
    "        make_random_graph(self.num_graph, self.stage_pool_path)\n",
    "\n",
    "        return create_toolbox_for_NSGA_RWNN(self.num_graph, self.args_train, self.stage_pool_path, self.data_path,\n",
    "                                            self.log_file_name)\n",
    "\n",
    "    ## Train\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "                \n",
    "        ## Parameters\n",
    "        self.create_toolbox()\n",
    "        POP_SIZE = self.pop_size\n",
    "\n",
    "        ## train log\n",
    "        train_log = OrderedDict()\n",
    "\n",
    "        if self.toolbox is None:\n",
    "            self.toolbox = self.create_toolbox()\n",
    "        \n",
    "        if self.args_train.graycode:\n",
    "            gray_len = len(str(grayCode(self.num_graph)))\n",
    "\n",
    "        toolbox = self.toolbox\n",
    "\n",
    "        # log에 기록할 stats\n",
    "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "        stats.register(\"min\", np.min, axis=0)\n",
    "        stats.register(\"max\", np.max, axis=0)\n",
    "\n",
    "        logbook = tools.Logbook()\n",
    "        logbook.header = \"gen\", \"evals\", \"min\", \"max\", \"evals_time\", \"gen_time\"\n",
    "\n",
    "        # population 생성.  (toolbox.population은 creator.Individual n개를 담은 list를 반환. (=> population)\n",
    "        now = datetime.datetime.now()\n",
    "        now_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(\"Initialion starts ...\")\n",
    "        logging.info(\"Initialion starts at \" + now_str)\n",
    "        init_start_time = time.time()\n",
    "\n",
    "        pop = toolbox.population(n=POP_SIZE)\n",
    "\n",
    "        ## fitness, model list\n",
    "        fit_list = []\n",
    "        model_list = []\n",
    "        \n",
    "        local_min_fit1 = float('inf')\n",
    "        local_min_fit2 = float('inf')\n",
    "        local_min_index = [None, None]\n",
    "        \n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in pop if not ind.fitness.valid]\n",
    "        #fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)  # .evaluate는 tuple을 반환. 따라서 fitnesses는 튜플을 원소로 가지는 list\n",
    "    \n",
    "        checked_ind = []\n",
    "        checked_inds = []\n",
    "        for idx, ind in enumerate(invalid_ind):\n",
    "            if self.args_train.graycode:\n",
    "                for k in range(3):\n",
    "                    ind[gray_len*k:gray_len*(k+1)] = [x for x in check_Upper(ind[gray_len*k:gray_len*(k+1)],self.num_graph)]\n",
    "\n",
    "\n",
    "            fitness, ind_model = evaluate(ind,args_train=self.args_train, stage_pool_path=self.stage_pool_path,data_path=self.data_path ,log_file_name=self.log_file_name)\n",
    "            ind.fitness.values = fitness\n",
    "            fit_list.append(fitness)\n",
    "            model_list.append(ind_model)\n",
    "            \n",
    "            if fitness[0] < local_min_fit1:\n",
    "                local_min_fit1 = fitness[0]\n",
    "                local_min_index[0] = idx\n",
    "\n",
    "            if fitness[1] < local_min_fit2:\n",
    "                local_min_fit2 = fitness[1]\n",
    "                local_min_index[1] = idx\n",
    "\n",
    "        ## index ckpt download\n",
    "        print(\"#### Saving Model\", local_min_index)\n",
    "        self.save_model(model=model_list[local_min_index[0]],ngen=0,subname=str(0)+'_'+'acc')                          \n",
    "        self.save_model(model=model_list[local_min_index[1]],ngen=0,subname=str(0)+'_'+'flops')                          \n",
    "\n",
    "            \n",
    "        ## log 기록\n",
    "        train_log[0] = fit_list\n",
    "        self.train_log = train_log\n",
    "\n",
    "        # This is just to assign the crowding distance to the individuals\n",
    "        # no actual selection is done\n",
    "        pop = toolbox.select(pop, len(pop))\n",
    "\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=0, evals=len(invalid_ind), **record)\n",
    "        print(logbook.stream)\n",
    "\n",
    "        now = datetime.datetime.now()\n",
    "        now_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(\"Initialization is finished at\", now_str)\n",
    "        logging.info(\"Initialion is finished at \" + now_str)\n",
    "\n",
    "        init_time = time.time() - init_start_time\n",
    "        logging.info(\"Initialion time = \" + str(init_time) + \"s\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        # Begin the generational process\n",
    "        for gen in range(1, self.ngen):\n",
    "            now = datetime.datetime.now()\n",
    "            now_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(\"#####\", gen, \"th generation starts at\", now_str)\n",
    "            logging.info(str(gen) + \"th generation starts at\" + now_str)\n",
    "\n",
    "            start_gen = time.time()\n",
    "            # Vary the population\n",
    "            offspring = tools.selTournamentDCD(pop, len(pop))\n",
    "            offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "\n",
    "            for ind1, ind2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() <= self.cxpb:\n",
    "                    toolbox.mate(ind1, ind2)\n",
    "\n",
    "                toolbox.mutate(ind1, indpb=self.mutpb)\n",
    "                toolbox.mutate(ind2, indpb=self.mutpb)\n",
    "                del ind1.fitness.values, ind2.fitness.values\n",
    "\n",
    "            # Evaluate the individuals with an invalid fitness\n",
    "            print(\"##### Evaluation starts\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            ## fitness value : accuracy ,flops 모음\n",
    "            fit_list = []\n",
    "            model_listist = []\n",
    "\n",
    "            ## 가장 최소 1,2 구하기\n",
    "            local_min_fit1 = float('inf')\n",
    "            local_min_fit2 = float('inf')\n",
    "            local_min_index = [None, None]\n",
    "\n",
    "            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "                 \n",
    "            \n",
    "            for idx,ind in enumerate(invalid_ind):\n",
    "                if self.args_train.graycode:\n",
    "                    for k in range(3):\n",
    "                        ind[gray_len*k:gray_len*(k+1)] = deepcopy(check_Upper(ind[gray_len*k:gray_len*(k+1)],self.num_graph))\n",
    "\n",
    "                fitness, ind_model = evaluate(ind,args_train=self.args_train, stage_pool_path=self.stage_pool_path,data_path=self.data_path ,log_file_name=self.log_file_name)\n",
    "                ind.fitness.values = fitness\n",
    "                fit_list.append(fitness)\n",
    "                model_list.append(ind_model)\n",
    "\n",
    "                if fitness[0] < local_min_fit1:\n",
    "                    local_min_fit1 = fitness[0]\n",
    "                    local_min_index[0] = idx\n",
    "\n",
    "                if fitness[1] < local_min_fit2:\n",
    "                    local_min_fit2 = fitness[1]\n",
    "                    local_min_index[1] = idx\n",
    "\n",
    "\n",
    "            ## index ckpt download\n",
    "            print(\"#### Saving Model\", local_min_index)\n",
    "            self.save_model(model=model_list[local_min_index[0]],ngen=gen,subname=str(gen)+'_'+'acc')                          \n",
    "            self.save_model(model=model_list[local_min_index[1]],ngen=gen,subname=str(gen)+'_'+'flops')                          \n",
    "\n",
    "            ## log 기록\n",
    "            train_log[gen] = fit_list\n",
    "            self.train_log = train_log\n",
    "\n",
    "            eval_time_for_one_generation = time.time() - start_time\n",
    "            print(\"##### Evaluation ends (Time : %.3f)\" % eval_time_for_one_generation)\n",
    "\n",
    "            # Select the next generation population\n",
    "            pop = toolbox.select(pop + offspring, POP_SIZE)\n",
    "\n",
    "            gen_time = time.time() - start_gen\n",
    "            print('##### [gen_time: %.3fs]' % gen_time, gen, 'th generation is finished.')\n",
    "\n",
    "            record = stats.compile(pop)\n",
    "            logbook.record(gen=gen, evals=len(invalid_ind), **record,\n",
    "                           evals_time=eval_time_for_one_generation, gen_time=gen_time)\n",
    "\n",
    "            logging.info('Gen [%03d/%03d] -- evals: %03d, evals_time: %.4fs, gen_time: %.4fs' % (\n",
    "            gen, self.ngen, len(invalid_ind), eval_time_for_one_generation, gen_time))\n",
    "            print(logbook.stream)\n",
    "\n",
    "    ## Save Check point\n",
    "\n",
    "    ## Save Log\n",
    "    def save_log(self):\n",
    "\n",
    "        log = self.log\n",
    "\n",
    "        ## 필요한 log 추후 정리하여 추l가\n",
    "        log['train_log'] = self.train_log\n",
    "\n",
    "        with open(self.train_log_file_name, 'w', encoding='utf-8') as make_file:\n",
    "            json.dump(log, make_file, ensure_ascii=False, indent='\\t')\n",
    "\n",
    "    ## Save Model\n",
    "    def save_model(self, model,ngen, subname):\n",
    "        \n",
    "        model_fname = self.name + '_' + str(ngen) + '_' + subname\n",
    "        model_path = os.path.join(self.model_dir, model_fname)\n",
    "        print(\"Saving Model\",model_path)\n",
    "        torch.save(model,model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARGS_TRAIN': {'base_lr': 0.1,\n",
      "                'batch_size': 32,\n",
      "                'data': 'CIFAR10',\n",
      "                'epochs': 1,\n",
      "                'graycode': True,\n",
      "                'input_dim': 3,\n",
      "                'lr_mode': 'cosine',\n",
      "                'momentum': 0.9,\n",
      "                'num_classes': 10,\n",
      "                'print_freq': 100,\n",
      "                'targetlr': 0.0,\n",
      "                'warmup_epochs': 0,\n",
      "                'warmup_lr': 0.0,\n",
      "                'warmup_mode': 'linear',\n",
      "                'weight_decay': 5e-05,\n",
      "                'workers': 4},\n",
      " 'CXPB': 0.5,\n",
      " 'DATA_PATH': 'D:/data/cifar10/',\n",
      " 'MUTPB': 0.5,\n",
      " 'NAME': 'num_classes_test',\n",
      " 'NGEN': 2,\n",
      " 'NUM_GRAPH': 100,\n",
      " 'POP_SIZE': 4,\n",
      " 'RUN_CODE': 'test_kyy_CIFAR10_time_check'}\n",
      "Start to make random graph pool...\n",
      "Finished\n",
      "Start to make random graph pool...\n",
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82103\\Anaconda3\\envs\\newrw\\lib\\site-packages\\deap\\creator.py:141: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\82103\\Anaconda3\\envs\\newrw\\lib\\site-packages\\deap\\creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to make random graph pool...\n",
      "Finished\n",
      "Initialion starts ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only assign an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e68066d2de86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrwns_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gray_code.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_toolbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnum_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-01623d73dc84>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraycode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                     \u001b[0mind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgray_len\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mgray_len\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_Upper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgray_len\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mgray_len\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only assign an iterable"
     ]
    }
   ],
   "source": [
    "num_class = rwns_train(\"gray_code.json\")\n",
    "num_class.create_toolbox()\n",
    "num_class.train()\n",
    "num_class.save_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-20d45705f8cb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-20d45705f8cb>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    a.del(0:2)\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a.del(0:2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del a[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'newrw'",
   "language": "python",
   "name": "newrw"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
