{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference] https://deap.readthedocs.io/en/master/examples/nsga3.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "from easydict import EasyDict\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn    # for hardware tunning (cudnn.benchmark = True)\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from thop import profile\n",
    "from thop import clever_format\n",
    "\n",
    "from lr_scheduler import LRScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. generation pool 구성하기 (Small RWNN 대상)\n",
    "\n",
    "- stage1, 2, 3에 쓸 random graph 100개 만들기 (가능한 조합수: 100 x 100 x 100) => 1M개의 조합 내에서 GA로 최적의 조합을 빠르게 찾자\n",
    "\n",
    "\n",
    "- 파일명 형식 = graphmodel_Nodes_K_P\n",
    "    \n",
    "    \n",
    "    e.g. WS_32_4_075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험을 위한 환경 셋팅\n",
    "run_code = 'test_kyy'\n",
    "stage_pool_path = './graph_pool' + '/' + run_code + '/'\n",
    "if not os.path.exists(stage_pool_path):\n",
    "    os.makedirs(stage_pool_path)\n",
    "    \n",
    "# make the log directory\n",
    "log_path = './logs/' + run_code + '/'\n",
    "if not os.path.isdir(log_path): os.makedirs(log_path)\n",
    "    \n",
    "logging.basicConfig(filename=log_path + 'logging.log', level=logging.INFO)\n",
    "logging.info('Start to write log.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### [모듈화 - 시작] util_graph_new #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(Nodes, args):\n",
    "    if args.graph_model == 'ER':\n",
    "        return nx.random_graphs.erdos_renyi_graph(Nodes, args.P)\n",
    "    elif args.graph_model == 'BA':\n",
    "        return nx.random_graphs.barabasi_albert_graph(Nodes, args.M)\n",
    "    elif args.graph_model == 'WS':\n",
    "        return nx.random_graphs.connected_watts_strogatz_graph(Nodes, args.K, args.P, tries=200)\n",
    "\n",
    "def save_graph(graph, path):\n",
    "    nx.write_yaml(graph, path)\n",
    "    \n",
    "def load_graph(path):\n",
    "    return nx.read_yaml(path)\n",
    "\n",
    "Node = collections.namedtuple('Node', ['id', 'inputs', 'type'])  # typename, field_names\n",
    "\n",
    "def get_graph_info(graph):\n",
    "    input_nodes = []\n",
    "    output_nodes = []\n",
    "    Nodes = []\n",
    "    for node in range(graph.number_of_nodes()):\n",
    "        # node i 에 대해        \n",
    "        tmp = list(graph.neighbors(node))\n",
    "        tmp.sort()    # 오름차순 정렬\n",
    "    \n",
    "        # node type 정의    \n",
    "        type = -1    # input node도, output node도 아닌. 그래프의 중간에 매개자처럼 있는 중간 node.\n",
    "        if node < tmp[0]:\n",
    "            input_nodes.append(node)\n",
    "            type = 0    # id 가장 작은 노드보다 작으면, 이건 외부에서 input을 받는 노드. 즉 input node.\n",
    "        if node > tmp[-1]:\n",
    "            output_nodes.append(node)\n",
    "            type = 1    # id 가장 큰 노드보다 크면, 이건 외부로 output 내보내는 노드. 즉 output node.\n",
    "        \n",
    "        # dag로 변환 (자신의 id보다 작은 노드들과의 연결만 남기기)\n",
    "        # [type] 0: input node, 1: output node, -1: input도 output도 아닌, 그래프 중간에 매개자처럼 있는 중간 node\n",
    "        Nodes.append(Node(node, [n for n in tmp if n < node], type))    # DAG(Directed Acyclic Graph)로 변환\n",
    "    return Nodes, input_nodes, output_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. random graph 100개 만들기\n",
    "#     - Nodes 수, K, P의 범위는 임의로 정함.\n",
    "#     - 일단 WS로만 만듦\n",
    "\n",
    "num_graph = 100     # 만들고자 하는 graph 수 (pool size)\n",
    "\n",
    "# 겹치는 그래프가 있을 경우, 100개 이하로 생성될 수 있으므로, saved 된 graph 파일수 체크하며 num_graph개 될때까지 생성.\n",
    "check_path = glob.glob(stage_pool_path + '*.yaml')\n",
    "check_file_num = len(check_path)\n",
    "\n",
    "while check_file_num < num_graph:\n",
    "    \n",
    "    Nodes = random.randint(20, 40)  # => [Nodes 값 수정 시 주의] 아래 K값은 Nodes보다 작아야함.\n",
    "    graph_model = 'WS'\n",
    "    K = random.randint(4, Nodes-10)  # [min, max] // WS에서는 K nearest. 따라서, 4 ~ 30 random 선택 하도록\n",
    "    P = round(random.uniform(0.25, 0.75), 2)   # 소수 둘째자리까지만 나오도록 반올림 => 결과 e.g. 0.75\n",
    "\n",
    "    args = EasyDict({'graph_model': graph_model, 'K':K, 'P':P})\n",
    "\n",
    "    P_str = str(P)[0] + str(P)[2:]   # 0.75 => 075\n",
    "    save_file_path = stage_pool_path + graph_model + '_' + str(Nodes) + '_' + str(K) + '_' + P_str + '.yaml'   # e.g. WS_32_4_075\n",
    "    \n",
    "    graph = build_graph(Nodes, args)\n",
    "    save_graph(graph, save_file_path)\n",
    "    \n",
    "    check_path = glob.glob(stage_pool_path + '*.yaml')\n",
    "    check_file_num = len(check_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### [모듈화 - 끝] util_graph_new #####\n",
    "\n",
    "# => 최종적으로, num_graph와 stage_pool_path 를 인수로 받아서, 해당 path에 num_graph 수 만큼의 그래프 떨궈주는 함수 만들기\n",
    "#    일단은 정해진 graph_model은 'WS', K, P 는 인수로 받지 말고 구현\n",
    "#      =>  이후에 확장하기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 크로모좀 설계 & fitness function 정의\n",
    "\n",
    "- 단순 리스트 ( 원소는 0 ~ 저장된 그래프 수, int )\n",
    "\n",
    "\n",
    "- e.g. [0, 5, 10] => (0번째 그래프, 5번째 그래프, 10번째 그래프)가 순서대로 stage1, 2, 3을 구성하는 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base, creator\n",
    "from deap import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# fitness function\n",
    "    input: [0, 5, 10]   하나의 크로모좀.\n",
    "\n",
    "    1) input인 [0, 5, 10]을 받아서 (0번째, 5번째, 10번째)에 해당하는 그래프 파일 각각 읽어와서 신경망 구축\n",
    "    \n",
    "    2) training (임시로 1 epoch. 실제 실험 시, RWNN과 같은 epoch 학습시키기)\n",
    "    \n",
    "    3) return flops, val_accuracy\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Classes and tools\n",
    "############################\n",
    "# => Min ( -val_accuracy(top_1),  flops )\n",
    "creator.create('FitnessMin', base.Fitness, weights=(-1.0, -1.0 ))  # name, base (class), attribute // \n",
    "creator.create('Individual', list, fitness=creator.FitnessMin)  # creator.FitnessMaxMin attribute로 가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Initialize\n",
    "############################\n",
    "IND_SIZE = 3    # 한 individual, 즉 하나의 chromosome은 3개의 graph. 즉, 3개의 stage를 가짐.\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# toolbox.attribute(0, (num_graph-1)) 이렇게 사용함.\n",
    "# 즉, 0 ~ (num_grpah - 1) 중 임의의 정수 선택. => 이걸 3번하면 하나의 small graph가 생김\n",
    "BOUND_LOW = 0\n",
    "BOUND_UP = num_graph-1\n",
    "toolbox.register('attr_int', random.randint, BOUND_LOW, BOUND_UP)   # register(alias, method, argument ...)\n",
    "\n",
    "# toolbox.attribute라는 함수를 n번 시행해서 containter인 creator.individual에 넣은 후 해당 instance를 반환함.\n",
    "# e.g. [0, 1, 3] 반환\n",
    "toolbox.register('individual', tools.initRepeat,\n",
    "                 creator.Individual, toolbox.attr_int, n=IND_SIZE)\n",
    "\n",
    "toolbox.register('population', tools.initRepeat,\n",
    "                 list, toolbox.individual)    # n은 생략함. toolbox.population 함수를 뒤에서 실행할 때 넣어줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 16, 41]\n",
      "[[5, 53, 92], [11, 64, 9], [78, 40, 59], [26, 28, 47], [16, 92, 4], [27, 78, 19], [16, 86, 96], [59, 97, 97]]\n"
     ]
    }
   ],
   "source": [
    "# 함수 테스트\n",
    "temp_ind = toolbox.individual()\n",
    "print(temp_ind)\n",
    "\n",
    "temp_pop_size = 8  # 4의 배수. for using 'tools.selTournamentDCD'\n",
    "temp_pop = toolbox.population(temp_pop_size)\n",
    "print(temp_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### [모듈화 - 시작] model_new.py #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class depthwise_separable_conv_3x3(nn.Module):\n",
    "    def __init__(self, nin, nout, stride):\n",
    "        # input node 일때, stride = 1; => size 유지\n",
    "        # input node 아닐 대, stride = 2; =>  (x-1)/2 + 1\n",
    "        super(depthwise_separable_conv_3x3, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(nin, nin, kernel_size=3, stride=stride, padding=1, groups=nin)\n",
    "        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1)  # default: stride=1, padding=0, dilation=1, groups=1, bias=True\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class Triplet_unit(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes, stride=1):\n",
    "        super(Triplet_unit, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = depthwise_separable_conv_3x3(inplanes, outplanes, stride)\n",
    "        self.bn = nn.BatchNorm2d(outplanes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(x)\n",
    "        out = self.conv(out)\n",
    "        out = self.bn(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class Node_OP(nn.Module):\n",
    "    def __init__(self, Node, inplanes, outplanes):\n",
    "        super(Node_OP, self).__init__()\n",
    "        self.is_input_node = Node.type == 0\n",
    "        self.input_nums = len(Node.inputs)    # 해당 Node에 input으로 연결된 노드의 개수\n",
    "\n",
    "        # input 개수가 1보다 크면, 여러 input을 합쳐야함.\n",
    "        if self.input_nums > 1:\n",
    "            self.mean_weight = nn.Parameter(torch.ones(self.input_nums))  # type: torch.nn.parameter.Parameter\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        if self.is_input_node:\n",
    "            self.conv = Triplet_unit(inplanes, outplanes, stride=2)   # Triplet_unit = relu, conv, bn\n",
    "        else:\n",
    "            self.conv = Triplet_unit(outplanes, outplanes, stride=1)\n",
    "\n",
    "    # [참고] nn.Sigmoid()(torch.ones(1)) = 0.7311\n",
    "    # seoungwonpark source 에서는 torch.zeros()로 들어감. => 0.5\n",
    "    def forward(self, *input):\n",
    "        if self.input_nums > 1:\n",
    "            out = self.sigmoid(self.mean_weight[0]) * input[0]\n",
    "            for i in range(1, self.input_nums):\n",
    "                out = out + self.sigmoid(self.mean_weight[i]) * input[i]\n",
    "        else:\n",
    "            out = input[0]\n",
    "        out = self.conv(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class StageBlock(nn.Module):\n",
    "    def __init__(self, graph, inplanes, outplanes):\n",
    "        super(StageBlock, self).__init__()\n",
    "        # graph를 input으로 받아서, Node_OP class. 즉, neural network graph로 전환함.\n",
    "        self.nodes, self.input_nodes, self.output_nodes = get_graph_info(graph)\n",
    "        self.nodeop  = nn.ModuleList()    # Holds submodules in a list.\n",
    "        for node in self.nodes:\n",
    "            # 각각의 node들을 Node_OP class로 만들어준 뒤, nn.ModuleList()인 self.nodeop에 append 해주기\n",
    "            self.nodeop.append(Node_OP(node, inplanes, outplanes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        results = {}\n",
    "        # input\n",
    "        for id in self.input_nodes:\n",
    "            results[id] = self.nodeop[id](x)  # input x를 먼저 graph's input node에 각각 넣어줌.\n",
    "\n",
    "        # graph 중간 계산\n",
    "        for id, node in enumerate(self.nodes):\n",
    "            # 각각의 노드 id에 대해\n",
    "            if id not in self.input_nodes:\n",
    "                # graph's input node가 아니라면, 그래프 내에서 해당 노드의 인풋들인 node.inputs의 output인 results[_id]\n",
    "                #    => 그 결과를 results[id]에 저장.\n",
    "                # self.nodeop[id]는 해당 id의 Node_OP. 즉, input들을 받아서 forward(모아서, conv 태우기)하는 것.\n",
    "                # 따라서, input으로 넣을 때 unpack 함.\n",
    "                # id 작은 노드부터 result를 차근차근 계산하면서, id를 올라감.\n",
    "                results[id] = self.nodeop[id](*[results[_id] for _id in node.inputs])\n",
    "\n",
    "        result = results[self.output_nodes[0]]\n",
    "        # output\n",
    "        # graph's output_nodes의 output 들을 평균내기\n",
    "        for idx, id in enumerate(self.output_nodes):\n",
    "            if idx > 0:\n",
    "                result = result + results[id]\n",
    "        result = result / len(self.output_nodes)\n",
    "        return result\n",
    "   \n",
    " \n",
    "# Node_OP -> StageBlock class 정의해놓고,\n",
    "# conv2, conv3, conv4에 각각 random graph 생성해서 모듈로 추가함\n",
    "# e.g.\n",
    "#  graphs = EasyDict({'stage_1': stage_1_graph,\n",
    "#                     'stage_2': stage_2_graph,\n",
    "#                     'stage_3': stage_3_graph\n",
    "#  })   # stage_1_graph = 해당 graph 파일의 path\n",
    "# channels = 109\n",
    "\n",
    "class RWNN(nn.Module):\n",
    "    def __init__(self, net_type, graphs, channels, num_classes=1000):\n",
    "        super(RWNN, self).__init__()\n",
    "        # 논문에서도 conv1 쪽은 예외적으로 Conv-BN 이라고 언급함. (나머지에서는 Conv-ReLU-BN 을 conv 로 표기) \n",
    "        self.conv1 = depthwise_separable_conv_3x3(3, channels // 2, 2)    # nin, nout, stride\n",
    "        self.bn1 = nn.BatchNorm2d(channels // 2)\n",
    "    \n",
    "        # 채널수 변화도, 논문에서처럼 conv2: C, conv3: 2C, conv4: 4C, conv5: 8C    \n",
    "        if net_type == 'small':\n",
    "            self.conv2 = Triplet_unit(channels // 2, channels, 2)    # inplanes, outplanes, stride=2\n",
    "\n",
    "            self.conv3 = StageBlock(graphs.stage_1, channels, channels)\n",
    " \n",
    "            self.conv4 = StageBlock(graphs.stage_2, channels, channels *2)   \n",
    "\n",
    "            self.conv5 = StageBlock(graphs.stage_3, channels * 2, channels * 4)\n",
    "\n",
    "            self.relu = nn.ReLU()\n",
    "            self.conv = nn.Conv2d(channels * 4, 1280, kernel_size=1)   # 마지막에 1x1 conv, 1280-d\n",
    "            self.bn2 = nn.BatchNorm2d(1280)\n",
    "        \n",
    "        #######################################\n",
    "        # 원 코드에서 regular 부분 지움\n",
    "        #######################################\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)  # 마지막은 global average pooling\n",
    "        self.fc = nn.Linear(1280, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    # torch.topk : input, k, dim=None, largest=True, sorted=True => returns top k element\n",
    "    # returns values list & indices list\n",
    "    _, pred = output.topk(maxk, 1, True, True)    \n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))   # torch.eq: Computes element-wise equality\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)   # input, dim,\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for one epoch\n",
    "def train(train_loader, model, criterion, optimizer, lr_scheduler, epoch, print_freq):\n",
    "    batch_time = AverageMeter()\n",
    "    epoch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        lr_scheduler.update(i, epoch)\n",
    "        \n",
    "        target = target.cuda(async=True)\n",
    "        \n",
    "        input_var = torch.autograd.Variable(input.cuda())\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "        \n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "        top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('\\t - Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                loss=losses, top1=top1, top5=top5))\n",
    "            \n",
    "#             logging.info('Epoch: [{0}][{1}/{2}]\\t'\n",
    "#                   'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "#                   'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "#                   'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "#                   'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "#                 epoch, i, len(train_loader), batch_time=batch_time,\n",
    "#                 data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
    "            \n",
    "            niter = epoch * len(train_loader) + i\n",
    "#             writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], niter)\n",
    "#             writer.add_scalar('Train/Avg_Loss', losses.avg, niter)\n",
    "#             writer.add_scalar('Train/Avg_Top1', top1.avg / 100.0, niter)\n",
    "#             writer.add_scalar('Train/Avg_Top5', top5.avg / 100.0, niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, epoch):\n",
    "#     batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            target = target.cuda(async=True)\n",
    "            input_var = torch.autograd.Variable(input.cuda())\n",
    "            target_var = torch.autograd.Variable(target)\n",
    "\n",
    "            # compute output\n",
    "            output = model(input_var)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec1.item(), input.size(0))\n",
    "            top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "#             batch_time.update(time.time() - end)   # 처음에 end랑 batch_time도 바꿈\n",
    "#             end = time.time()\n",
    "\n",
    "#             if i % args.print_freq == 0:\n",
    "#                 print('Test: [{0}/{1}]\\t'\n",
    "#                       'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "#                       'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "#                       'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "#                       'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "#                     i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "#                     top1=top1, top5=top5))\n",
    "                \n",
    "#                 logging.info('Test: [{0}/{1}]\\t'\n",
    "#                       'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "#                       'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "#                       'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "#                       'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "#                     i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "#                     top1=top1, top5=top5))          \n",
    "                \n",
    "        # measure elapsed time\n",
    "        validation_time = time.time() - start\n",
    "\n",
    "        print('Validation_time {validation_time:.3f} Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "              .format(validation_time=validation_time, top1=top1, top5=top5))\n",
    "\n",
    "        niter = (epoch + 1)\n",
    "#         writer.add_scalar('Eval/Avg_Loss', losses.avg, niter)\n",
    "#         writer.add_scalar('Eval/Avg_Top1', top1.avg / 100.0, niter)\n",
    "#         writer.add_scalar('Eval/Avg_Top5', top5.avg / 100.0, niter)\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Operators\n",
    "############################\n",
    "def evaluate(individual, args_train):  # individual\n",
    "    # list 형식의 individual 객체를 input으로 받음   e.g. [0, 4, 17] \n",
    "    # 1) load graph\n",
    "    total_graph_path = glob.glob(stage_pool_path + '*.yaml')    # list\n",
    "    \n",
    "    stage_1_graph = load_graph(total_graph_path[individual[0]])\n",
    "    stage_2_graph = load_graph(total_graph_path[individual[1]])\n",
    "    stage_3_graph = load_graph(total_graph_path[individual[2]])\n",
    "    \n",
    "    graphs = EasyDict({'stage_1': stage_1_graph,\n",
    "                       'stage_2': stage_2_graph,\n",
    "                       'stage_3': stage_3_graph\n",
    "                      })\n",
    "\n",
    "    # 2) build RWNN\n",
    "    channels = 109\n",
    "    NN_model = RWNN(net_type='small', graphs=graphs, channels=channels)\n",
    "    NN_model.cuda()\n",
    "    \n",
    "    ###########################\n",
    "    # Flops 계산 - [Debug] nn.DataParallele (for multi-gpu) 적용 전에 확인.\n",
    "    ###########################\n",
    "    input_flops = torch.randn(1, 3, 224, 224).cuda()\n",
    "    flops, params = profile(NN_model, inputs=(input_flops, ), verbose=False)\n",
    "    \n",
    "    # 3) Prepare for train\n",
    "    NN_model = nn.DataParallel(NN_model)  # for multi-GPU\n",
    "    \n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    optimizer = torch.optim.SGD(NN_model.parameters(), args_train.base_lr,\n",
    "                                momentum=args_train.momentum,\n",
    "                                weight_decay=args_train.weight_decay)\n",
    "    \n",
    "    start_epoch  = 0\n",
    "    best_prec1 = 0    \n",
    "    \n",
    "    cudnn.benchmark = True    # This flag allows you to enable the inbuilt cudnn auto-tuner to find the best algorithm to use for your hardware.  \n",
    "    \n",
    "    ###########################\n",
    "    # Dataset & Dataloader\n",
    "    ###########################\n",
    "    train_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),   # 추가함\n",
    "            transforms.Resize(224),    # 추가함.  imagenet dataset과 size 맞추기\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # rescale 0 ~ 1 => -1 ~ 1\n",
    "        ])\n",
    "\n",
    "    val_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(224),    # 추가함.  imagenet dataset과 size 맞추기\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # rescale 0 ~ 1 => -1 ~ 1\n",
    "        ])\n",
    "\n",
    "\n",
    "    # 이미 다운 받아놨으니 download=False\n",
    "    # 데이터가 없을 경우, 처음엔느 download=True 로 설정해놓고 실행해주어야함\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=False, transform=train_transform)\n",
    "\n",
    "    val_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=False, transform=val_transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args_train.batch_size,\n",
    "                                              shuffle=True, num_workers=args_train.workers)  \n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args_train.batch_size,\n",
    "                                             shuffle=False, num_workers=args_train.workers)    \n",
    "    \n",
    "    ###########################\n",
    "    # Train\n",
    "    ###########################\n",
    "    niters = len(train_loader)\n",
    "\n",
    "    lr_scheduler = LRScheduler(optimizer, niters, args_train)  # (default) args.step = [30, 60, 90], args.decay_factor = 0.1, args.power = 2.0    \n",
    "    \n",
    "    for epoch in range(start_epoch, args_train.epochs):\n",
    "        # train for one epoch\n",
    "        train(train_loader, NN_model, criterion, optimizer, lr_scheduler, epoch, args_train.print_freq)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, NN_model, criterion, epoch)\n",
    "        \n",
    "        # remember best prec@1 and save checkpoint\n",
    "#         is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "    \n",
    "    return -best_prec1, flops   # Min (-val_accuracy, flops) 이므로 val_accuracy(top1)에 - 붙여서 return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### [모듈화 - 끝] model_new.py #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### [모듈화 - 시작] GA_operator_new.py #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 mutUniformInt에 xrange() 함수가 사용됐어서, range로 수정함.\n",
    "import random\n",
    "\n",
    "from itertools import repeat\n",
    "from collections import Sequence\n",
    "\n",
    "def mutUniformInt_custom(individual, low, up, indpb):\n",
    "    \"\"\"Mutate an individual by replacing attributes, with probability *indpb*,\n",
    "    by a integer uniformly drawn between *low* and *up* inclusively.\n",
    "    :param individual: :term:`Sequence <sequence>` individual to be mutated.\n",
    "    :param low: The lower bound or a :term:`python:sequence` of\n",
    "                of lower bounds of the range from wich to draw the new\n",
    "                integer.\n",
    "    :param up: The upper bound or a :term:`python:sequence` of\n",
    "               of upper bounds of the range from wich to draw the new\n",
    "               integer.\n",
    "    :param indpb: Independent probability for each attribute to be mutated.\n",
    "    :returns: A tuple of one individual.\n",
    "    \"\"\"\n",
    "    size = len(individual)\n",
    "    if not isinstance(low, Sequence):\n",
    "        low = repeat(low, size)\n",
    "    elif len(low) < size:\n",
    "        raise IndexError(\"low must be at least the size of individual: %d < %d\" % (len(low), size))\n",
    "    if not isinstance(up, Sequence):\n",
    "        up = repeat(up, size)\n",
    "    elif len(up) < size:\n",
    "        raise IndexError(\"up must be at least the size of individual: %d < %d\" % (len(up), size))\n",
    "\n",
    "    for i, xl, xu in zip(range(size), low, up):\n",
    "        if random.random() < indpb:\n",
    "            individual[i] = random.randint(xl, xu)\n",
    "\n",
    "    return individual,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### [모듈화 - 끝] GA_operator_new.py #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 'args_train' for evaluation\n",
    "args_train = EasyDict({\n",
    "    'lr_mode': 'cosine',\n",
    "    'warmup_mode': 'linear',    # default\n",
    "    'base_lr': 0.1,\n",
    "    'momentum': 0.9, \n",
    "    'weight_decay': 0.00005 ,\n",
    "    'print_freq': 100,\n",
    "\n",
    "    'epochs': 2,\n",
    "    'batch_size': 128,\n",
    "\n",
    "    'workers': 2,\n",
    "\n",
    "    'warmup_epochs': 0,\n",
    "    'warmup_lr': 0.0,\n",
    "    'targetlr': 0.0\n",
    "\n",
    "})\n",
    "\n",
    "# toolbox.mate(), toolbox.select() 등의 이름으로 해당 함수에 접근할 수 있음.\n",
    "toolbox.register('mate', tools.cxTwoPoint)  # crossover\n",
    "\n",
    "toolbox.register('mutate', mutUniformInt_custom, low=BOUND_LOW, up=BOUND_UP)\n",
    "# indpb: 뒤쪽에서 쓸 때, MUTPB로 넣어줌. individual의 각 원소에 mutation 적용될 확률\n",
    "# indpb – Independent probability for each attribute to be mutated.\n",
    "\n",
    "toolbox.register('select', tools.selNSGA2, nd='standard')  # selection.  // k – The number of individuals to select. k는 함수 쓸 때 받아야함\n",
    "# => return A list of selected individuals.\n",
    "# tools.selTournament의 arguement 중 torunsize는 미리 지정해줌\n",
    "\n",
    "toolbox.register('evaluate', evaluate, args_train=args_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind1: [5, 53, 92]\n",
      "ind2: [11, 64, 9]\n",
      "cx_results: ([5, 64, 92], [11, 53, 9])\n",
      "mu_results (ind1): ([5, 5, 44],)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fc14e1902ed9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mu_results (ind1):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-752f76a8ff99>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(individual, args_train)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNN_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-9f700b403eaf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, lr_scheduler, epoch, print_freq)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 함수 test \n",
    "ind1 = temp_pop[0]\n",
    "ind2 = temp_pop[1]\n",
    "print(\"ind1:\", ind1)\n",
    "print(\"ind2:\", ind2)\n",
    "\n",
    "cx_results = toolbox.mate(ind1, ind2)  # crossover\n",
    "print(\"cx_results:\", cx_results)\n",
    "\n",
    "MUTPB = 0.8  # test를 위해 높게 잡음\n",
    "mu_results = toolbox.mutate(ind1, indpb=MUTPB)\n",
    "print(\"mu_results (ind1):\", mu_results)\n",
    "\n",
    "val_accuracy, flops = toolbox.evaluate(ind1)\n",
    "\n",
    "print()\n",
    "print(val_accuracy, flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_pop:\n",
      "   [[5, 5, 44], [11, 53, 9], [78, 40, 59], [26, 28, 47], [16, 92, 4], [27, 78, 19], [16, 86, 96], [59, 97, 97]]\n",
      "temp_offspring:\n",
      "   [[11, 53, 9], [26, 28, 47], [26, 28, 47], [59, 97, 97], [59, 97, 97], [5, 5, 44], [78, 40, 59], [16, 86, 96]]\n"
     ]
    }
   ],
   "source": [
    "# 함수 test \n",
    "# This is just to assign the crowding distance to the individuals's fitness\n",
    "# no actual selection is done\n",
    "temp_pop = toolbox.select(temp_pop, len(temp_pop))\n",
    "print(\"temp_pop:\\n  \", temp_pop)\n",
    "\n",
    "# Vary the population\n",
    "temp_offspring = tools.selTournamentDCD(temp_pop, len(temp_pop))  # selTournamentDCD: individuals length must be a multiple of 4\n",
    "temp_offspring = [toolbox.clone(ind) for ind in temp_offspring]\n",
    "print(\"temp_offspring:\\n  \", temp_offspring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialion starts ...\n",
      "\t - Epoch: [0][0/391]\tTime 2.880 (2.880)\tLoss 6.8524 (6.8524)\tPrec@1 0.000 (0.000)\tPrec@5 4.688 (4.688)\n",
      "\t - Epoch: [0][100/391]\tTime 0.488 (0.504)\tLoss 1.8076 (2.1814)\tPrec@1 23.438 (23.670)\tPrec@5 87.500 (76.501)\n",
      "\t - Epoch: [0][200/391]\tTime 0.486 (0.486)\tLoss 1.6248 (1.9706)\tPrec@1 42.969 (29.085)\tPrec@5 91.406 (81.522)\n",
      "\t - Epoch: [0][300/391]\tTime 0.422 (0.478)\tLoss 1.4427 (1.8336)\tPrec@1 50.000 (33.602)\tPrec@5 95.312 (84.614)\n",
      "Validation_time 19.142 Prec@1 48.260 Prec@5 92.680\n",
      "\t - Epoch: [1][0/391]\tTime 1.700 (1.700)\tLoss 1.3869 (1.3869)\tPrec@1 50.000 (50.000)\tPrec@5 95.312 (95.312)\n",
      "\t - Epoch: [1][100/391]\tTime 0.420 (0.466)\tLoss 1.1805 (1.3301)\tPrec@1 53.125 (51.586)\tPrec@5 96.094 (93.270)\n",
      "\t - Epoch: [1][200/391]\tTime 0.419 (0.460)\tLoss 1.0791 (1.2705)\tPrec@1 67.188 (53.867)\tPrec@5 96.875 (94.220)\n",
      "\t - Epoch: [1][300/391]\tTime 0.505 (0.456)\tLoss 1.0067 (1.2144)\tPrec@1 61.719 (56.131)\tPrec@5 96.875 (94.825)\n",
      "Validation_time 18.191 Prec@1 63.820 Prec@5 96.780\n",
      "\t - Epoch: [0][0/391]\tTime 0.822 (0.822)\tLoss 6.8904 (6.8904)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.351 (0.362)\tLoss 1.9407 (2.2620)\tPrec@1 26.562 (20.985)\tPrec@5 78.906 (73.360)\n",
      "\t - Epoch: [0][200/391]\tTime 0.325 (0.358)\tLoss 1.6875 (2.0575)\tPrec@1 39.844 (26.547)\tPrec@5 87.500 (78.747)\n",
      "\t - Epoch: [0][300/391]\tTime 0.344 (0.356)\tLoss 1.9028 (1.9440)\tPrec@1 30.469 (30.002)\tPrec@5 83.594 (81.691)\n",
      "Validation_time 14.637 Prec@1 42.040 Prec@5 90.330\n",
      "\t - Epoch: [1][0/391]\tTime 0.823 (0.823)\tLoss 1.5942 (1.5942)\tPrec@1 42.188 (42.188)\tPrec@5 92.188 (92.188)\n",
      "\t - Epoch: [1][100/391]\tTime 0.339 (0.358)\tLoss 1.3868 (1.5047)\tPrec@1 46.094 (44.322)\tPrec@5 92.969 (91.785)\n",
      "\t - Epoch: [1][200/391]\tTime 0.399 (0.358)\tLoss 1.3912 (1.4633)\tPrec@1 48.438 (46.416)\tPrec@5 92.188 (92.355)\n",
      "\t - Epoch: [1][300/391]\tTime 0.346 (0.359)\tLoss 1.2871 (1.4167)\tPrec@1 52.344 (48.264)\tPrec@5 92.188 (92.712)\n",
      "Validation_time 14.918 Prec@1 54.490 Prec@5 94.870\n",
      "\t - Epoch: [0][0/391]\tTime 0.881 (0.881)\tLoss 6.9410 (6.9410)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.474 (0.441)\tLoss 2.0244 (2.2719)\tPrec@1 31.250 (21.620)\tPrec@5 78.125 (73.360)\n",
      "\t - Epoch: [0][200/391]\tTime 0.434 (0.437)\tLoss 1.7002 (2.0493)\tPrec@1 35.156 (26.963)\tPrec@5 87.500 (78.770)\n",
      "\t - Epoch: [0][300/391]\tTime 0.468 (0.437)\tLoss 1.5560 (1.9239)\tPrec@1 43.750 (30.526)\tPrec@5 89.062 (81.966)\n",
      "Validation_time 17.381 Prec@1 40.680 Prec@5 90.980\n",
      "\t - Epoch: [1][0/391]\tTime 0.806 (0.806)\tLoss 1.4998 (1.4998)\tPrec@1 45.312 (45.312)\tPrec@5 92.969 (92.969)\n",
      "\t - Epoch: [1][100/391]\tTime 0.419 (0.439)\tLoss 1.3942 (1.4720)\tPrec@1 55.469 (46.040)\tPrec@5 94.531 (91.801)\n",
      "\t - Epoch: [1][200/391]\tTime 0.410 (0.438)\tLoss 1.4605 (1.4201)\tPrec@1 48.438 (48.204)\tPrec@5 91.406 (92.428)\n",
      "\t - Epoch: [1][300/391]\tTime 0.425 (0.438)\tLoss 1.1692 (1.3740)\tPrec@1 53.906 (49.956)\tPrec@5 97.656 (92.925)\n",
      "Validation_time 17.626 Prec@1 56.890 Prec@5 95.730\n",
      "\t - Epoch: [0][0/391]\tTime 1.527 (1.527)\tLoss 7.0003 (7.0003)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.786 (0.761)\tLoss 1.8293 (2.2403)\tPrec@1 32.031 (22.138)\tPrec@5 86.719 (75.077)\n",
      "\t - Epoch: [0][200/391]\tTime 0.725 (0.761)\tLoss 1.7793 (2.0183)\tPrec@1 28.125 (27.635)\tPrec@5 85.156 (80.294)\n",
      "\t - Epoch: [0][300/391]\tTime 0.732 (0.762)\tLoss 1.5696 (1.8903)\tPrec@1 35.938 (31.603)\tPrec@5 89.844 (83.469)\n",
      "Validation_time 27.863 Prec@1 46.040 Prec@5 92.520\n",
      "\t - Epoch: [1][0/391]\tTime 1.146 (1.146)\tLoss 1.5917 (1.5917)\tPrec@1 39.844 (39.844)\tPrec@5 90.625 (90.625)\n",
      "\t - Epoch: [1][100/391]\tTime 0.740 (0.761)\tLoss 1.3471 (1.3877)\tPrec@1 49.219 (49.389)\tPrec@5 94.531 (93.015)\n",
      "\t - Epoch: [1][200/391]\tTime 0.786 (0.764)\tLoss 1.1392 (1.3282)\tPrec@1 60.156 (51.807)\tPrec@5 94.531 (93.560)\n",
      "\t - Epoch: [1][300/391]\tTime 0.720 (0.763)\tLoss 1.0311 (1.2689)\tPrec@1 67.969 (54.122)\tPrec@5 96.094 (94.225)\n",
      "Validation_time 27.943 Prec@1 63.650 Prec@5 96.350\n",
      "\t - Epoch: [0][0/391]\tTime 1.051 (1.051)\tLoss 6.9231 (6.9231)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.483 (0.475)\tLoss 2.0133 (2.1612)\tPrec@1 28.906 (24.915)\tPrec@5 77.344 (76.965)\n",
      "\t - Epoch: [0][200/391]\tTime 0.443 (0.476)\tLoss 1.5518 (1.9602)\tPrec@1 44.531 (29.711)\tPrec@5 85.156 (81.988)\n",
      "\t - Epoch: [0][300/391]\tTime 0.480 (0.475)\tLoss 1.5137 (1.8377)\tPrec@1 46.094 (33.511)\tPrec@5 91.406 (84.614)\n",
      "Validation_time 18.690 Prec@1 49.650 Prec@5 93.350\n",
      "\t - Epoch: [1][0/391]\tTime 0.911 (0.911)\tLoss 1.4003 (1.4003)\tPrec@1 44.531 (44.531)\tPrec@5 93.750 (93.750)\n",
      "\t - Epoch: [1][100/391]\tTime 0.504 (0.471)\tLoss 1.2206 (1.3158)\tPrec@1 61.719 (52.506)\tPrec@5 93.750 (93.773)\n",
      "\t - Epoch: [1][200/391]\tTime 0.458 (0.471)\tLoss 1.2193 (1.2548)\tPrec@1 52.344 (54.785)\tPrec@5 93.750 (94.368)\n",
      "\t - Epoch: [1][300/391]\tTime 0.441 (0.471)\tLoss 1.1758 (1.2017)\tPrec@1 57.031 (56.772)\tPrec@5 93.750 (94.928)\n",
      "Validation_time 18.909 Prec@1 64.960 Prec@5 96.810\n",
      "\t - Epoch: [0][0/391]\tTime 1.404 (1.404)\tLoss 6.9993 (6.9993)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.790 (0.792)\tLoss 2.0375 (2.1699)\tPrec@1 21.875 (24.729)\tPrec@5 80.469 (76.400)\n",
      "\t - Epoch: [0][200/391]\tTime 0.765 (0.787)\tLoss 1.6977 (1.9711)\tPrec@1 39.062 (29.734)\tPrec@5 88.281 (81.262)\n",
      "\t - Epoch: [0][300/391]\tTime 0.783 (0.785)\tLoss 1.6054 (1.8516)\tPrec@1 46.875 (33.098)\tPrec@5 88.281 (84.087)\n",
      "Validation_time 28.963 Prec@1 45.860 Prec@5 92.000\n",
      "\t - Epoch: [1][0/391]\tTime 1.183 (1.183)\tLoss 1.2796 (1.2796)\tPrec@1 54.688 (54.688)\tPrec@5 96.094 (96.094)\n",
      "\t - Epoch: [1][100/391]\tTime 0.896 (0.790)\tLoss 1.5535 (1.3882)\tPrec@1 45.312 (48.863)\tPrec@5 86.719 (93.270)\n",
      "\t - Epoch: [1][200/391]\tTime 0.799 (0.788)\tLoss 1.2873 (1.3412)\tPrec@1 53.125 (51.073)\tPrec@5 96.094 (93.843)\n",
      "\t - Epoch: [1][300/391]\tTime 0.766 (0.785)\tLoss 1.0662 (1.2954)\tPrec@1 60.156 (52.987)\tPrec@5 97.656 (94.228)\n",
      "Validation_time 29.884 Prec@1 59.940 Prec@5 96.240\n",
      "\t - Epoch: [0][0/391]\tTime 1.040 (1.040)\tLoss 6.9112 (6.9112)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.424 (0.439)\tLoss 1.8564 (2.1717)\tPrec@1 30.469 (23.956)\tPrec@5 81.250 (76.570)\n",
      "\t - Epoch: [0][200/391]\tTime 0.403 (0.431)\tLoss 1.7897 (1.9551)\tPrec@1 34.375 (29.668)\tPrec@5 85.938 (81.856)\n",
      "\t - Epoch: [0][300/391]\tTime 0.436 (0.431)\tLoss 1.3502 (1.8222)\tPrec@1 50.781 (33.910)\tPrec@5 93.750 (84.858)\n",
      "Validation_time 18.619 Prec@1 50.770 Prec@5 93.810\n",
      "\t - Epoch: [1][0/391]\tTime 0.859 (0.859)\tLoss 1.3901 (1.3901)\tPrec@1 47.656 (47.656)\tPrec@5 96.094 (96.094)\n",
      "\t - Epoch: [1][100/391]\tTime 0.431 (0.431)\tLoss 1.3879 (1.3010)\tPrec@1 55.469 (53.226)\tPrec@5 93.750 (93.943)\n",
      "\t - Epoch: [1][200/391]\tTime 0.481 (0.430)\tLoss 1.1076 (1.2457)\tPrec@1 59.375 (55.290)\tPrec@5 95.312 (94.590)\n",
      "\t - Epoch: [1][300/391]\tTime 0.403 (0.429)\tLoss 1.1260 (1.2000)\tPrec@1 60.156 (57.094)\tPrec@5 94.531 (95.009)\n",
      "Validation_time 18.768 Prec@1 63.650 Prec@5 96.710\n",
      "\t - Epoch: [0][0/391]\tTime 1.096 (1.096)\tLoss 6.9191 (6.9191)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.605 (0.638)\tLoss 1.7837 (2.2035)\tPrec@1 39.062 (23.739)\tPrec@5 88.281 (76.330)\n",
      "\t - Epoch: [0][200/391]\tTime 0.616 (0.634)\tLoss 1.6794 (1.9853)\tPrec@1 32.031 (29.038)\tPrec@5 89.844 (81.514)\n",
      "\t - Epoch: [0][300/391]\tTime 0.596 (0.633)\tLoss 1.5484 (1.8742)\tPrec@1 42.188 (32.231)\tPrec@5 88.281 (83.978)\n",
      "Validation_time 24.100 Prec@1 44.290 Prec@5 91.340\n",
      "\t - Epoch: [1][0/391]\tTime 1.241 (1.241)\tLoss 1.4550 (1.4550)\tPrec@1 40.625 (40.625)\tPrec@5 89.062 (89.062)\n",
      "\t - Epoch: [1][100/391]\tTime 0.607 (0.636)\tLoss 1.3560 (1.4272)\tPrec@1 48.438 (47.386)\tPrec@5 93.750 (92.273)\n",
      "\t - Epoch: [1][200/391]\tTime 0.614 (0.633)\tLoss 1.2290 (1.3729)\tPrec@1 56.250 (49.845)\tPrec@5 95.312 (92.988)\n",
      "\t - Epoch: [1][300/391]\tTime 0.650 (0.633)\tLoss 1.1760 (1.3213)\tPrec@1 60.938 (51.721)\tPrec@5 94.531 (93.599)\n",
      "Validation_time 24.219 Prec@1 59.100 Prec@5 96.110\n",
      "gen\tevals\tmin                              \tmax                              \tevals_time\tgen_time\n",
      "0  \t8    \t[-6.49600000e+01  1.51653555e+09]\t[-5.44900000e+01  2.06400806e+09]\t          \t        \n",
      "Initialization is finished.\n",
      "\n",
      "##### 1 th generation starts\n",
      "##### Evaluation starts\n",
      "\t - Epoch: [0][0/391]\tTime 1.143 (1.143)\tLoss 6.9348 (6.9348)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Epoch: [0][100/391]\tTime 0.559 (0.589)\tLoss 1.9264 (2.2298)\tPrec@1 27.344 (22.912)\tPrec@5 83.594 (73.963)\n",
      "\t - Epoch: [0][200/391]\tTime 0.566 (0.581)\tLoss 1.8154 (2.0062)\tPrec@1 32.031 (28.179)\tPrec@5 86.719 (79.827)\n",
      "\t - Epoch: [0][300/391]\tTime 0.593 (0.579)\tLoss 1.5704 (1.8910)\tPrec@1 47.656 (31.629)\tPrec@5 85.156 (82.740)\n",
      "Validation_time 22.081 Prec@1 45.440 Prec@5 93.410\n",
      "\t - Epoch: [1][0/391]\tTime 1.052 (1.052)\tLoss 1.3596 (1.3596)\tPrec@1 42.969 (42.969)\tPrec@5 96.875 (96.875)\n",
      "\t - Epoch: [1][100/391]\tTime 0.607 (0.581)\tLoss 1.3614 (1.3789)\tPrec@1 50.000 (49.304)\tPrec@5 94.531 (93.015)\n",
      "\t - Epoch: [1][200/391]\tTime 0.619 (0.575)\tLoss 1.3279 (1.3302)\tPrec@1 50.781 (51.403)\tPrec@5 96.094 (93.602)\n",
      "\t - Epoch: [1][300/391]\tTime 0.559 (0.574)\tLoss 1.3548 (1.2806)\tPrec@1 54.688 (53.457)\tPrec@5 92.969 (94.126)\n",
      "Validation_time 22.127 Prec@1 61.650 Prec@5 96.270\n",
      "\t - Epoch: [0][0/391]\tTime 0.930 (0.930)\tLoss 6.9697 (6.9697)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.333 (0.351)\tLoss 1.8196 (2.1603)\tPrec@1 32.812 (25.131)\tPrec@5 82.031 (76.586)\n",
      "\t - Epoch: [0][200/391]\tTime 0.354 (0.349)\tLoss 1.6200 (1.9365)\tPrec@1 42.969 (31.013)\tPrec@5 87.500 (82.078)\n",
      "\t - Epoch: [0][300/391]\tTime 0.333 (0.349)\tLoss 1.6292 (1.8207)\tPrec@1 41.406 (34.523)\tPrec@5 87.500 (84.821)\n",
      "Validation_time 14.203 Prec@1 47.100 Prec@5 92.590\n",
      "\t - Epoch: [1][0/391]\tTime 0.795 (0.795)\tLoss 1.4332 (1.4332)\tPrec@1 49.219 (49.219)\tPrec@5 89.844 (89.844)\n",
      "\t - Epoch: [1][100/391]\tTime 0.322 (0.350)\tLoss 1.1369 (1.3791)\tPrec@1 60.156 (49.420)\tPrec@5 96.875 (93.062)\n",
      "\t - Epoch: [1][200/391]\tTime 0.361 (0.349)\tLoss 1.2220 (1.3331)\tPrec@1 53.906 (51.341)\tPrec@5 94.531 (93.699)\n",
      "\t - Epoch: [1][300/391]\tTime 0.412 (0.349)\tLoss 1.2485 (1.2857)\tPrec@1 57.812 (53.133)\tPrec@5 93.750 (94.207)\n",
      "Validation_time 14.452 Prec@1 59.900 Prec@5 96.150\n",
      "\t - Epoch: [0][0/391]\tTime 1.004 (1.004)\tLoss 6.8995 (6.8995)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.452 (0.425)\tLoss 1.9064 (2.2169)\tPrec@1 25.000 (23.151)\tPrec@5 82.031 (74.714)\n",
      "\t - Epoch: [0][200/391]\tTime 0.436 (0.421)\tLoss 1.7909 (2.0015)\tPrec@1 31.250 (28.323)\tPrec@5 85.938 (80.302)\n",
      "\t - Epoch: [0][300/391]\tTime 0.432 (0.419)\tLoss 1.4958 (1.8803)\tPrec@1 46.094 (31.979)\tPrec@5 92.188 (83.363)\n",
      "Validation_time 16.830 Prec@1 43.340 Prec@5 91.620\n",
      "\t - Epoch: [1][0/391]\tTime 0.759 (0.759)\tLoss 1.5356 (1.5356)\tPrec@1 45.312 (45.312)\tPrec@5 91.406 (91.406)\n",
      "\t - Epoch: [1][100/391]\tTime 0.423 (0.418)\tLoss 1.4780 (1.4247)\tPrec@1 47.656 (47.308)\tPrec@5 92.188 (92.953)\n",
      "\t - Epoch: [1][200/391]\tTime 0.449 (0.420)\tLoss 1.2803 (1.3730)\tPrec@1 53.125 (49.405)\tPrec@5 92.969 (93.431)\n",
      "\t - Epoch: [1][300/391]\tTime 0.451 (0.420)\tLoss 1.0992 (1.3254)\tPrec@1 67.188 (51.492)\tPrec@5 96.875 (93.872)\n",
      "Validation_time 17.465 Prec@1 59.440 Prec@5 95.890\n",
      "\t - Epoch: [0][0/391]\tTime 0.943 (0.943)\tLoss 6.8753 (6.8753)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.523 (0.529)\tLoss 1.9962 (2.2529)\tPrec@1 28.906 (22.308)\tPrec@5 80.469 (73.430)\n",
      "\t - Epoch: [0][200/391]\tTime 0.496 (0.525)\tLoss 1.6947 (2.0412)\tPrec@1 41.406 (27.678)\tPrec@5 86.719 (78.840)\n",
      "\t - Epoch: [0][300/391]\tTime 0.561 (0.524)\tLoss 1.6861 (1.9295)\tPrec@1 41.406 (31.081)\tPrec@5 84.375 (81.707)\n",
      "Validation_time 20.288 Prec@1 43.340 Prec@5 91.060\n",
      "\t - Epoch: [1][0/391]\tTime 0.915 (0.915)\tLoss 1.5840 (1.5840)\tPrec@1 39.062 (39.062)\tPrec@5 90.625 (90.625)\n",
      "\t - Epoch: [1][100/391]\tTime 0.543 (0.530)\tLoss 1.4584 (1.5093)\tPrec@1 45.312 (44.539)\tPrec@5 92.969 (91.004)\n",
      "\t - Epoch: [1][200/391]\tTime 0.516 (0.526)\tLoss 1.4446 (1.4643)\tPrec@1 48.438 (46.171)\tPrec@5 92.188 (91.865)\n",
      "\t - Epoch: [1][300/391]\tTime 0.500 (0.526)\tLoss 1.1783 (1.4247)\tPrec@1 57.031 (47.757)\tPrec@5 96.875 (92.369)\n",
      "Validation_time 20.541 Prec@1 54.530 Prec@5 94.850\n",
      "\t - Epoch: [0][0/391]\tTime 1.049 (1.049)\tLoss 6.9474 (6.9474)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.596 (0.644)\tLoss 1.9946 (2.2216)\tPrec@1 24.219 (22.966)\tPrec@5 82.031 (75.062)\n",
      "\t - Epoch: [0][200/391]\tTime 0.681 (0.642)\tLoss 1.8884 (2.0059)\tPrec@1 30.469 (28.428)\tPrec@5 86.719 (80.465)\n",
      "\t - Epoch: [0][300/391]\tTime 0.607 (0.641)\tLoss 1.6930 (1.8941)\tPrec@1 32.031 (31.873)\tPrec@5 92.188 (83.145)\n",
      "Validation_time 23.183 Prec@1 44.070 Prec@5 91.990\n",
      "\t - Epoch: [1][0/391]\tTime 1.036 (1.036)\tLoss 1.4225 (1.4225)\tPrec@1 50.000 (50.000)\tPrec@5 93.750 (93.750)\n",
      "\t - Epoch: [1][100/391]\tTime 0.645 (0.639)\tLoss 1.3034 (1.4339)\tPrec@1 57.031 (47.262)\tPrec@5 93.750 (92.404)\n",
      "\t - Epoch: [1][200/391]\tTime 0.655 (0.639)\tLoss 1.2782 (1.3683)\tPrec@1 57.031 (50.120)\tPrec@5 89.062 (93.346)\n",
      "\t - Epoch: [1][300/391]\tTime 0.621 (0.639)\tLoss 1.2560 (1.3159)\tPrec@1 56.250 (52.292)\tPrec@5 92.969 (93.898)\n",
      "Validation_time 22.912 Prec@1 60.100 Prec@5 96.350\n",
      "\t - Epoch: [0][0/391]\tTime 0.936 (0.936)\tLoss 6.8845 (6.8845)\tPrec@1 0.000 (0.000)\tPrec@5 1.562 (1.562)\n",
      "\t - Epoch: [0][100/391]\tTime 0.334 (0.369)\tLoss 1.9041 (2.2622)\tPrec@1 28.125 (22.587)\tPrec@5 85.938 (73.909)\n",
      "\t - Epoch: [0][200/391]\tTime 0.347 (0.367)\tLoss 1.7612 (2.0278)\tPrec@1 32.031 (27.884)\tPrec@5 87.500 (79.925)\n",
      "\t - Epoch: [0][300/391]\tTime 0.391 (0.366)\tLoss 1.5084 (1.9108)\tPrec@1 41.406 (31.089)\tPrec@5 92.188 (82.810)\n",
      "Validation_time 15.151 Prec@1 45.050 Prec@5 91.910\n",
      "\t - Epoch: [1][0/391]\tTime 0.701 (0.701)\tLoss 1.6022 (1.6022)\tPrec@1 39.844 (39.844)\tPrec@5 89.844 (89.844)\n",
      "\t - Epoch: [1][100/391]\tTime 0.342 (0.369)\tLoss 1.2940 (1.4633)\tPrec@1 53.906 (46.527)\tPrec@5 92.969 (92.157)\n",
      "\t - Epoch: [1][200/391]\tTime 0.367 (0.369)\tLoss 1.4036 (1.4187)\tPrec@1 49.219 (48.123)\tPrec@5 91.406 (92.786)\n",
      "\t - Epoch: [1][300/391]\tTime 0.410 (0.367)\tLoss 1.3541 (1.3810)\tPrec@1 55.469 (49.504)\tPrec@5 91.406 (93.213)\n",
      "Validation_time 15.419 Prec@1 56.120 Prec@5 95.190\n",
      "\t - Epoch: [0][0/391]\tTime 0.965 (0.965)\tLoss 6.8666 (6.8666)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.459 (0.489)\tLoss 1.8221 (2.2109)\tPrec@1 28.125 (23.438)\tPrec@5 85.938 (74.288)\n",
      "\t - Epoch: [0][200/391]\tTime 0.451 (0.489)\tLoss 1.7472 (1.9857)\tPrec@1 31.250 (29.147)\tPrec@5 87.500 (80.348)\n",
      "\t - Epoch: [0][300/391]\tTime 0.449 (0.489)\tLoss 1.5981 (1.8699)\tPrec@1 42.969 (32.517)\tPrec@5 92.188 (83.352)\n",
      "Validation_time 19.820 Prec@1 48.970 Prec@5 93.280\n",
      "\t - Epoch: [1][0/391]\tTime 0.881 (0.881)\tLoss 1.4417 (1.4417)\tPrec@1 42.188 (42.188)\tPrec@5 94.531 (94.531)\n",
      "\t - Epoch: [1][100/391]\tTime 0.461 (0.492)\tLoss 1.3007 (1.3636)\tPrec@1 53.125 (49.930)\tPrec@5 93.750 (93.495)\n",
      "\t - Epoch: [1][200/391]\tTime 0.464 (0.488)\tLoss 1.0946 (1.3158)\tPrec@1 63.281 (52.079)\tPrec@5 96.875 (93.851)\n",
      "\t - Epoch: [1][300/391]\tTime 0.527 (0.488)\tLoss 1.1167 (1.2655)\tPrec@1 59.375 (54.080)\tPrec@5 96.875 (94.313)\n",
      "Validation_time 19.770 Prec@1 61.650 Prec@5 96.330\n",
      "\t - Epoch: [0][0/391]\tTime 0.879 (0.879)\tLoss 6.9568 (6.9568)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.366 (0.406)\tLoss 1.9191 (2.2989)\tPrec@1 28.906 (20.421)\tPrec@5 81.250 (70.769)\n",
      "\t - Epoch: [0][200/391]\tTime 0.415 (0.401)\tLoss 1.7854 (2.0645)\tPrec@1 31.250 (26.376)\tPrec@5 87.500 (77.740)\n",
      "\t - Epoch: [0][300/391]\tTime 0.374 (0.401)\tLoss 1.6181 (1.9369)\tPrec@1 38.281 (30.352)\tPrec@5 90.625 (81.172)\n",
      "Validation_time 16.671 Prec@1 40.590 Prec@5 88.690\n",
      "\t - Epoch: [1][0/391]\tTime 0.873 (0.873)\tLoss 1.5716 (1.5716)\tPrec@1 42.969 (42.969)\tPrec@5 88.281 (88.281)\n",
      "\t - Epoch: [1][100/391]\tTime 0.364 (0.407)\tLoss 1.5240 (1.4724)\tPrec@1 42.969 (46.504)\tPrec@5 91.406 (91.770)\n",
      "\t - Epoch: [1][200/391]\tTime 0.375 (0.405)\tLoss 1.3941 (1.4116)\tPrec@1 52.344 (48.675)\tPrec@5 94.531 (92.677)\n",
      "\t - Epoch: [1][300/391]\tTime 0.374 (0.404)\tLoss 1.2272 (1.3695)\tPrec@1 55.469 (50.376)\tPrec@5 94.531 (93.145)\n",
      "Validation_time 16.297 Prec@1 57.470 Prec@5 95.460\n",
      "##### Evaluation ends (Time : 3253.265)\n",
      "##### [gen_time: 3253.266s] 1 th generation is finished.\n",
      "1  \t8    \t[-6.49600000e+01  1.46135194e+09]\t[-5.61200000e+01  1.74673242e+09]\t3253.27   \t3253.27 \n",
      "##### 2 th generation starts\n",
      "##### Evaluation starts\n",
      "\t - Epoch: [0][0/391]\tTime 0.884 (0.884)\tLoss 7.0253 (7.0253)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.443 (0.470)\tLoss 1.8860 (2.2709)\tPrec@1 32.812 (21.326)\tPrec@5 80.469 (72.950)\n",
      "\t - Epoch: [0][200/391]\tTime 0.455 (0.472)\tLoss 1.6141 (2.0257)\tPrec@1 43.750 (27.546)\tPrec@5 90.625 (79.439)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Epoch: [0][300/391]\tTime 0.452 (0.471)\tLoss 1.4812 (1.8983)\tPrec@1 42.188 (31.613)\tPrec@5 92.188 (82.633)\n",
      "Validation_time 18.300 Prec@1 47.090 Prec@5 92.330\n",
      "\t - Epoch: [1][0/391]\tTime 1.103 (1.103)\tLoss 1.3408 (1.3408)\tPrec@1 52.344 (52.344)\tPrec@5 92.969 (92.969)\n",
      "\t - Epoch: [1][100/391]\tTime 0.511 (0.474)\tLoss 1.3642 (1.4335)\tPrec@1 49.219 (47.463)\tPrec@5 93.750 (92.574)\n",
      "\t - Epoch: [1][200/391]\tTime 0.484 (0.471)\tLoss 1.2491 (1.3805)\tPrec@1 56.250 (49.436)\tPrec@5 93.750 (93.097)\n",
      "\t - Epoch: [1][300/391]\tTime 0.438 (0.471)\tLoss 1.2049 (1.3302)\tPrec@1 57.812 (51.614)\tPrec@5 94.531 (93.586)\n",
      "Validation_time 18.617 Prec@1 58.740 Prec@5 95.530\n",
      "\t - Epoch: [0][0/391]\tTime 0.810 (0.810)\tLoss 6.8724 (6.8724)\tPrec@1 0.000 (0.000)\tPrec@5 3.125 (3.125)\n",
      "\t - Epoch: [0][100/391]\tTime 0.397 (0.433)\tLoss 1.8234 (2.2008)\tPrec@1 32.031 (23.221)\tPrec@5 85.938 (75.843)\n",
      "\t - Epoch: [0][200/391]\tTime 0.397 (0.429)\tLoss 1.5539 (1.9867)\tPrec@1 46.094 (28.549)\tPrec@5 87.500 (81.122)\n",
      "\t - Epoch: [0][300/391]\tTime 0.438 (0.427)\tLoss 1.4411 (1.8533)\tPrec@1 42.188 (32.794)\tPrec@5 96.094 (83.996)\n",
      "Validation_time 17.480 Prec@1 47.410 Prec@5 92.860\n",
      "\t - Epoch: [1][0/391]\tTime 0.962 (0.962)\tLoss 1.2686 (1.2686)\tPrec@1 58.594 (58.594)\tPrec@5 92.969 (92.969)\n",
      "\t - Epoch: [1][100/391]\tTime 0.465 (0.430)\tLoss 1.1489 (1.3016)\tPrec@1 58.594 (52.475)\tPrec@5 97.656 (93.928)\n",
      "\t - Epoch: [1][200/391]\tTime 0.405 (0.428)\tLoss 1.1382 (1.2550)\tPrec@1 61.719 (54.567)\tPrec@5 94.531 (94.415)\n",
      "\t - Epoch: [1][300/391]\tTime 0.425 (0.426)\tLoss 0.9890 (1.2039)\tPrec@1 61.719 (56.486)\tPrec@5 97.656 (94.762)\n",
      "Validation_time 17.701 Prec@1 64.670 Prec@5 96.620\n",
      "\t - Epoch: [0][0/391]\tTime 0.970 (0.970)\tLoss 6.8858 (6.8858)\tPrec@1 0.000 (0.000)\tPrec@5 1.562 (1.562)\n",
      "\t - Epoch: [0][100/391]\tTime 0.488 (0.511)\tLoss 1.9914 (2.1550)\tPrec@1 28.125 (24.861)\tPrec@5 78.906 (77.390)\n",
      "\t - Epoch: [0][200/391]\tTime 0.554 (0.506)\tLoss 1.8337 (1.9626)\tPrec@1 32.812 (29.921)\tPrec@5 84.375 (81.973)\n",
      "\t - Epoch: [0][300/391]\tTime 0.497 (0.507)\tLoss 1.5343 (1.8382)\tPrec@1 47.656 (33.498)\tPrec@5 89.062 (84.686)\n",
      "Validation_time 20.028 Prec@1 47.110 Prec@5 92.080\n",
      "\t - Epoch: [1][0/391]\tTime 1.012 (1.012)\tLoss 1.5821 (1.5821)\tPrec@1 42.969 (42.969)\tPrec@5 89.844 (89.844)\n",
      "\t - Epoch: [1][100/391]\tTime 0.498 (0.511)\tLoss 1.3597 (1.3382)\tPrec@1 56.250 (51.137)\tPrec@5 92.969 (93.541)\n",
      "\t - Epoch: [1][200/391]\tTime 0.508 (0.508)\tLoss 1.0771 (1.2872)\tPrec@1 60.156 (53.261)\tPrec@5 96.094 (94.100)\n",
      "\t - Epoch: [1][300/391]\tTime 0.525 (0.506)\tLoss 1.2589 (1.2439)\tPrec@1 57.812 (55.261)\tPrec@5 89.844 (94.591)\n",
      "Validation_time 20.285 Prec@1 62.480 Prec@5 96.450\n",
      "\t - Epoch: [0][0/391]\tTime 0.834 (0.834)\tLoss 6.9220 (6.9220)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.468 (0.457)\tLoss 1.9622 (2.2136)\tPrec@1 24.219 (23.430)\tPrec@5 82.031 (75.704)\n",
      "\t - Epoch: [0][200/391]\tTime 0.431 (0.455)\tLoss 1.7049 (1.9815)\tPrec@1 35.938 (28.906)\tPrec@5 89.062 (81.227)\n",
      "\t - Epoch: [0][300/391]\tTime 0.450 (0.456)\tLoss 1.5500 (1.8610)\tPrec@1 31.250 (32.605)\tPrec@5 92.188 (83.983)\n",
      "Validation_time 18.491 Prec@1 48.710 Prec@5 93.600\n",
      "\t - Epoch: [1][0/391]\tTime 1.189 (1.189)\tLoss 1.4462 (1.4462)\tPrec@1 50.000 (50.000)\tPrec@5 90.625 (90.625)\n",
      "\t - Epoch: [1][100/391]\tTime 0.552 (0.460)\tLoss 1.1005 (1.3569)\tPrec@1 59.375 (50.108)\tPrec@5 97.656 (93.572)\n",
      "\t - Epoch: [1][200/391]\tTime 0.438 (0.457)\tLoss 1.2332 (1.3025)\tPrec@1 57.031 (52.456)\tPrec@5 92.969 (94.135)\n",
      "\t - Epoch: [1][300/391]\tTime 0.431 (0.455)\tLoss 1.1960 (1.2573)\tPrec@1 57.031 (54.283)\tPrec@5 95.312 (94.498)\n",
      "Validation_time 18.486 Prec@1 62.180 Prec@5 96.400\n",
      "\t - Epoch: [0][0/391]\tTime 0.884 (0.884)\tLoss 6.9541 (6.9541)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.498 (0.526)\tLoss 1.7027 (2.1801)\tPrec@1 33.594 (23.716)\tPrec@5 86.719 (76.601)\n",
      "\t - Epoch: [0][200/391]\tTime 0.534 (0.527)\tLoss 1.6047 (1.9662)\tPrec@1 40.625 (29.412)\tPrec@5 89.062 (81.759)\n",
      "\t - Epoch: [0][300/391]\tTime 0.505 (0.526)\tLoss 1.4644 (1.8451)\tPrec@1 46.875 (33.272)\tPrec@5 92.188 (84.383)\n",
      "Validation_time 20.721 Prec@1 47.210 Prec@5 92.130\n",
      "\t - Epoch: [1][0/391]\tTime 0.913 (0.913)\tLoss 1.4921 (1.4921)\tPrec@1 45.312 (45.312)\tPrec@5 91.406 (91.406)\n",
      "\t - Epoch: [1][100/391]\tTime 0.539 (0.526)\tLoss 1.3965 (1.4130)\tPrec@1 48.438 (47.966)\tPrec@5 93.750 (93.054)\n",
      "\t - Epoch: [1][200/391]\tTime 0.559 (0.528)\tLoss 1.1981 (1.3558)\tPrec@1 46.875 (50.369)\tPrec@5 95.312 (93.513)\n",
      "\t - Epoch: [1][300/391]\tTime 0.528 (0.528)\tLoss 1.0805 (1.3076)\tPrec@1 57.812 (52.328)\tPrec@5 96.875 (93.903)\n",
      "Validation_time 20.880 Prec@1 59.400 Prec@5 95.800\n",
      "\t - Epoch: [0][0/391]\tTime 0.926 (0.926)\tLoss 6.8705 (6.8705)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.322 (0.342)\tLoss 1.8757 (2.2040)\tPrec@1 31.250 (24.018)\tPrec@5 84.375 (74.876)\n",
      "\t - Epoch: [0][200/391]\tTime 0.341 (0.342)\tLoss 1.6402 (1.9701)\tPrec@1 41.406 (29.796)\tPrec@5 87.500 (80.760)\n",
      "\t - Epoch: [0][300/391]\tTime 0.329 (0.340)\tLoss 1.5835 (1.8486)\tPrec@1 39.062 (33.415)\tPrec@5 89.062 (83.749)\n",
      "Validation_time 14.552 Prec@1 46.530 Prec@5 90.970\n",
      "\t - Epoch: [1][0/391]\tTime 0.776 (0.776)\tLoss 1.5555 (1.5555)\tPrec@1 45.312 (45.312)\tPrec@5 91.406 (91.406)\n",
      "\t - Epoch: [1][100/391]\tTime 0.328 (0.342)\tLoss 1.4121 (1.3797)\tPrec@1 48.438 (49.752)\tPrec@5 90.625 (92.644)\n",
      "\t - Epoch: [1][200/391]\tTime 0.319 (0.342)\tLoss 1.0511 (1.3153)\tPrec@1 58.594 (52.352)\tPrec@5 99.219 (93.630)\n",
      "\t - Epoch: [1][300/391]\tTime 0.432 (0.341)\tLoss 1.0854 (1.2678)\tPrec@1 61.719 (54.223)\tPrec@5 95.312 (94.251)\n",
      "Validation_time 14.291 Prec@1 61.160 Prec@5 96.090\n",
      "\t - Epoch: [0][0/391]\tTime 0.797 (0.797)\tLoss 6.9229 (6.9229)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.362 (0.363)\tLoss 1.7865 (2.2051)\tPrec@1 33.594 (22.734)\tPrec@5 83.594 (76.176)\n",
      "\t - Epoch: [0][200/391]\tTime 0.349 (0.358)\tLoss 1.5688 (1.9779)\tPrec@1 43.750 (28.926)\tPrec@5 89.062 (81.507)\n",
      "\t - Epoch: [0][300/391]\tTime 0.333 (0.357)\tLoss 1.5394 (1.8545)\tPrec@1 46.875 (32.794)\tPrec@5 89.844 (84.284)\n",
      "Validation_time 14.907 Prec@1 43.620 Prec@5 90.530\n",
      "\t - Epoch: [1][0/391]\tTime 0.831 (0.831)\tLoss 1.4061 (1.4061)\tPrec@1 47.656 (47.656)\tPrec@5 94.531 (94.531)\n",
      "\t - Epoch: [1][100/391]\tTime 0.388 (0.360)\tLoss 1.4976 (1.3734)\tPrec@1 47.656 (50.503)\tPrec@5 90.625 (93.000)\n",
      "\t - Epoch: [1][200/391]\tTime 0.347 (0.359)\tLoss 1.1635 (1.3242)\tPrec@1 64.062 (52.208)\tPrec@5 94.531 (93.614)\n",
      "\t - Epoch: [1][300/391]\tTime 0.335 (0.359)\tLoss 1.1520 (1.2823)\tPrec@1 57.812 (53.878)\tPrec@5 92.188 (94.074)\n",
      "Validation_time 14.780 Prec@1 61.190 Prec@5 95.890\n",
      "\t - Epoch: [0][0/391]\tTime 1.074 (1.074)\tLoss 6.8908 (6.8908)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.674 (0.708)\tLoss 1.8485 (2.2005)\tPrec@1 29.688 (23.314)\tPrec@5 82.812 (75.240)\n",
      "\t - Epoch: [0][200/391]\tTime 0.706 (0.705)\tLoss 1.6900 (2.0050)\tPrec@1 39.844 (28.230)\tPrec@5 90.625 (80.006)\n",
      "\t - Epoch: [0][300/391]\tTime 0.725 (0.702)\tLoss 1.6961 (1.8923)\tPrec@1 39.844 (31.772)\tPrec@5 88.281 (82.833)\n",
      "Validation_time 27.029 Prec@1 41.190 Prec@5 91.290\n",
      "\t - Epoch: [1][0/391]\tTime 1.105 (1.105)\tLoss 1.5142 (1.5142)\tPrec@1 39.062 (39.062)\tPrec@5 94.531 (94.531)\n",
      "\t - Epoch: [1][100/391]\tTime 0.686 (0.712)\tLoss 1.1569 (1.4281)\tPrec@1 51.562 (47.881)\tPrec@5 97.656 (92.667)\n",
      "\t - Epoch: [1][200/391]\tTime 0.761 (0.710)\tLoss 1.3167 (1.3739)\tPrec@1 55.469 (49.926)\tPrec@5 94.531 (93.241)\n",
      "\t - Epoch: [1][300/391]\tTime 0.737 (0.704)\tLoss 1.2468 (1.3247)\tPrec@1 58.594 (51.965)\tPrec@5 93.750 (93.742)\n",
      "Validation_time 26.877 Prec@1 59.900 Prec@5 96.210\n",
      "##### Evaluation ends (Time : 3276.616)\n",
      "##### [gen_time: 3276.617s] 2 th generation is finished.\n",
      "2  \t8    \t[-6.49600000e+01  1.38388634e+09]\t[-5.61200000e+01  1.74673242e+09]\t3276.62   \t3276.62 \n",
      "##### 3 th generation starts\n",
      "##### Evaluation starts\n",
      "\t - Epoch: [0][0/391]\tTime 0.741 (0.741)\tLoss 6.9242 (6.9242)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.316 (0.334)\tLoss 1.9032 (2.1684)\tPrec@1 35.156 (25.665)\tPrec@5 78.125 (77.112)\n",
      "\t - Epoch: [0][200/391]\tTime 0.355 (0.332)\tLoss 1.6259 (1.9523)\tPrec@1 34.375 (30.546)\tPrec@5 90.625 (82.090)\n",
      "\t - Epoch: [0][300/391]\tTime 0.307 (0.333)\tLoss 1.6423 (1.8286)\tPrec@1 38.281 (34.178)\tPrec@5 89.062 (84.798)\n",
      "Validation_time 14.135 Prec@1 51.540 Prec@5 93.980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Epoch: [1][0/391]\tTime 0.794 (0.794)\tLoss 1.3710 (1.3710)\tPrec@1 50.000 (50.000)\tPrec@5 91.406 (91.406)\n",
      "\t - Epoch: [1][100/391]\tTime 0.320 (0.339)\tLoss 1.1294 (1.2694)\tPrec@1 61.719 (53.914)\tPrec@5 93.750 (94.369)\n",
      "\t - Epoch: [1][200/391]\tTime 0.329 (0.338)\tLoss 1.1809 (1.2105)\tPrec@1 60.156 (56.374)\tPrec@5 95.312 (94.908)\n",
      "\t - Epoch: [1][300/391]\tTime 0.383 (0.337)\tLoss 1.1007 (1.1541)\tPrec@1 57.031 (58.563)\tPrec@5 96.094 (95.390)\n",
      "Validation_time 14.310 Prec@1 66.030 Prec@5 97.220\n",
      "\t - Epoch: [0][0/391]\tTime 1.104 (1.104)\tLoss 6.9622 (6.9622)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.562 (0.539)\tLoss 1.8760 (2.2076)\tPrec@1 29.688 (23.120)\tPrec@5 82.031 (74.698)\n",
      "\t - Epoch: [0][200/391]\tTime 0.517 (0.539)\tLoss 1.5507 (1.9766)\tPrec@1 43.750 (29.069)\tPrec@5 89.844 (80.935)\n",
      "\t - Epoch: [0][300/391]\tTime 0.554 (0.539)\tLoss 1.5953 (1.8455)\tPrec@1 42.188 (33.358)\tPrec@5 89.062 (83.978)\n",
      "Validation_time 20.940 Prec@1 48.220 Prec@5 92.950\n",
      "\t - Epoch: [1][0/391]\tTime 0.874 (0.874)\tLoss 1.2514 (1.2514)\tPrec@1 57.031 (57.031)\tPrec@5 92.188 (92.188)\n",
      "\t - Epoch: [1][100/391]\tTime 0.559 (0.543)\tLoss 1.0494 (1.3143)\tPrec@1 62.500 (52.498)\tPrec@5 95.312 (93.874)\n",
      "\t - Epoch: [1][200/391]\tTime 0.567 (0.543)\tLoss 1.1210 (1.2592)\tPrec@1 60.938 (54.501)\tPrec@5 94.531 (94.543)\n",
      "\t - Epoch: [1][300/391]\tTime 0.516 (0.540)\tLoss 0.9568 (1.2124)\tPrec@1 67.969 (56.271)\tPrec@5 97.656 (94.861)\n",
      "Validation_time 20.941 Prec@1 64.330 Prec@5 96.580\n",
      "\t - Epoch: [0][0/391]\tTime 0.747 (0.747)\tLoss 6.9486 (6.9486)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.357 (0.368)\tLoss 1.9800 (2.2324)\tPrec@1 25.781 (21.906)\tPrec@5 81.250 (74.706)\n",
      "\t - Epoch: [0][200/391]\tTime 0.352 (0.365)\tLoss 1.6891 (2.0100)\tPrec@1 42.969 (27.970)\tPrec@5 81.250 (80.449)\n",
      "\t - Epoch: [0][300/391]\tTime 0.343 (0.366)\tLoss 1.5645 (1.8935)\tPrec@1 38.281 (31.613)\tPrec@5 88.281 (83.173)\n",
      "Validation_time 15.421 Prec@1 45.790 Prec@5 92.460\n",
      "\t - Epoch: [1][0/391]\tTime 0.767 (0.767)\tLoss 1.4174 (1.4174)\tPrec@1 49.219 (49.219)\tPrec@5 91.406 (91.406)\n",
      "\t - Epoch: [1][100/391]\tTime 0.363 (0.369)\tLoss 1.3815 (1.4377)\tPrec@1 45.312 (47.587)\tPrec@5 92.188 (92.234)\n",
      "\t - Epoch: [1][200/391]\tTime 0.344 (0.367)\tLoss 1.2179 (1.3873)\tPrec@1 57.812 (49.495)\tPrec@5 96.094 (92.996)\n",
      "\t - Epoch: [1][300/391]\tTime 0.343 (0.366)\tLoss 1.1097 (1.3403)\tPrec@1 57.031 (51.248)\tPrec@5 97.656 (93.470)\n",
      "Validation_time 15.390 Prec@1 58.320 Prec@5 95.560\n",
      "\t - Epoch: [0][0/391]\tTime 1.023 (1.023)\tLoss 6.9220 (6.9220)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.476 (0.491)\tLoss 1.8136 (2.1997)\tPrec@1 31.250 (24.103)\tPrec@5 85.938 (76.106)\n",
      "\t - Epoch: [0][200/391]\tTime 0.490 (0.490)\tLoss 1.7015 (1.9934)\tPrec@1 41.406 (29.011)\tPrec@5 84.375 (80.993)\n",
      "\t - Epoch: [0][300/391]\tTime 0.470 (0.487)\tLoss 1.5712 (1.8729)\tPrec@1 40.625 (32.641)\tPrec@5 89.844 (83.739)\n",
      "Validation_time 20.188 Prec@1 45.330 Prec@5 91.750\n",
      "\t - Epoch: [1][0/391]\tTime 0.979 (0.979)\tLoss 1.6563 (1.6563)\tPrec@1 37.500 (37.500)\tPrec@5 92.188 (92.188)\n",
      "\t - Epoch: [1][100/391]\tTime 0.463 (0.483)\tLoss 1.3731 (1.4321)\tPrec@1 49.219 (47.409)\tPrec@5 90.625 (92.389)\n",
      "\t - Epoch: [1][200/391]\tTime 0.524 (0.481)\tLoss 1.4447 (1.3726)\tPrec@1 45.312 (49.549)\tPrec@5 95.312 (93.186)\n",
      "\t - Epoch: [1][300/391]\tTime 0.461 (0.481)\tLoss 1.4319 (1.3230)\tPrec@1 57.031 (51.674)\tPrec@5 89.062 (93.706)\n",
      "Validation_time 19.828 Prec@1 58.390 Prec@5 95.910\n",
      "\t - Epoch: [0][0/391]\tTime 0.848 (0.848)\tLoss 6.9062 (6.9062)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.314 (0.351)\tLoss 1.6942 (2.1527)\tPrec@1 35.938 (25.549)\tPrec@5 91.406 (76.849)\n",
      "\t - Epoch: [0][200/391]\tTime 0.326 (0.348)\tLoss 1.7237 (1.9355)\tPrec@1 35.156 (30.873)\tPrec@5 91.406 (82.331)\n",
      "\t - Epoch: [0][300/391]\tTime 0.394 (0.347)\tLoss 1.6175 (1.8074)\tPrec@1 43.750 (34.686)\tPrec@5 89.062 (85.099)\n",
      "Validation_time 14.760 Prec@1 49.920 Prec@5 92.910\n",
      "\t - Epoch: [1][0/391]\tTime 0.782 (0.782)\tLoss 1.2920 (1.2920)\tPrec@1 53.125 (53.125)\tPrec@5 93.750 (93.750)\n",
      "\t - Epoch: [1][100/391]\tTime 0.337 (0.351)\tLoss 1.1579 (1.2840)\tPrec@1 60.156 (53.133)\tPrec@5 94.531 (94.593)\n",
      "\t - Epoch: [1][200/391]\tTime 0.401 (0.349)\tLoss 0.9926 (1.2261)\tPrec@1 64.062 (55.648)\tPrec@5 98.438 (95.040)\n",
      "\t - Epoch: [1][300/391]\tTime 0.413 (0.348)\tLoss 1.1184 (1.1746)\tPrec@1 62.500 (57.685)\tPrec@5 94.531 (95.458)\n",
      "Validation_time 14.935 Prec@1 64.230 Prec@5 96.720\n",
      "\t - Epoch: [0][0/391]\tTime 0.912 (0.912)\tLoss 6.9169 (6.9169)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.555 (0.569)\tLoss 1.8192 (2.2261)\tPrec@1 28.906 (23.546)\tPrec@5 86.719 (75.534)\n",
      "\t - Epoch: [0][200/391]\tTime 0.633 (0.571)\tLoss 1.8144 (2.0220)\tPrec@1 28.906 (28.082)\tPrec@5 87.500 (80.488)\n",
      "\t - Epoch: [0][300/391]\tTime 0.542 (0.571)\tLoss 1.6633 (1.8963)\tPrec@1 37.500 (31.738)\tPrec@5 87.500 (83.282)\n",
      "Validation_time 21.984 Prec@1 45.960 Prec@5 91.940\n",
      "\t - Epoch: [1][0/391]\tTime 0.974 (0.974)\tLoss 1.4880 (1.4880)\tPrec@1 46.094 (46.094)\tPrec@5 92.969 (92.969)\n",
      "\t - Epoch: [1][100/391]\tTime 0.564 (0.572)\tLoss 1.2458 (1.3943)\tPrec@1 53.125 (48.902)\tPrec@5 96.094 (92.574)\n",
      "\t - Epoch: [1][200/391]\tTime 0.618 (0.573)\tLoss 1.2667 (1.3291)\tPrec@1 56.250 (51.574)\tPrec@5 92.969 (93.528)\n",
      "\t - Epoch: [1][300/391]\tTime 0.614 (0.571)\tLoss 1.2436 (1.2805)\tPrec@1 54.688 (53.649)\tPrec@5 96.094 (93.986)\n",
      "Validation_time 22.002 Prec@1 61.760 Prec@5 96.340\n",
      "\t - Epoch: [0][0/391]\tTime 0.878 (0.878)\tLoss 6.9017 (6.9017)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.346 (0.316)\tLoss 1.7681 (2.2172)\tPrec@1 36.719 (23.801)\tPrec@5 89.062 (74.180)\n",
      "\t - Epoch: [0][200/391]\tTime 0.288 (0.312)\tLoss 1.6782 (1.9826)\tPrec@1 37.500 (29.334)\tPrec@5 81.250 (80.543)\n",
      "\t - Epoch: [0][300/391]\tTime 0.298 (0.311)\tLoss 1.4993 (1.8516)\tPrec@1 47.656 (33.441)\tPrec@5 91.406 (83.734)\n",
      "Validation_time 12.702 Prec@1 43.660 Prec@5 92.380\n",
      "\t - Epoch: [1][0/391]\tTime 0.825 (0.825)\tLoss 1.4740 (1.4740)\tPrec@1 42.188 (42.188)\tPrec@5 92.188 (92.188)\n",
      "\t - Epoch: [1][100/391]\tTime 0.297 (0.311)\tLoss 1.3249 (1.3080)\tPrec@1 52.344 (52.847)\tPrec@5 93.750 (93.920)\n",
      "\t - Epoch: [1][200/391]\tTime 0.381 (0.310)\tLoss 1.1642 (1.2532)\tPrec@1 51.562 (54.742)\tPrec@5 96.875 (94.523)\n",
      "\t - Epoch: [1][300/391]\tTime 0.300 (0.309)\tLoss 1.0753 (1.2015)\tPrec@1 60.938 (56.660)\tPrec@5 94.531 (94.949)\n",
      "Validation_time 13.052 Prec@1 64.240 Prec@5 96.610\n",
      "\t - Epoch: [0][0/391]\tTime 0.978 (0.978)\tLoss 6.9659 (6.9659)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.621 (0.578)\tLoss 1.7710 (2.1623)\tPrec@1 39.844 (24.288)\tPrec@5 83.594 (76.632)\n",
      "\t - Epoch: [0][200/391]\tTime 0.550 (0.574)\tLoss 1.6477 (1.9486)\tPrec@1 39.844 (30.344)\tPrec@5 89.844 (81.670)\n",
      "\t - Epoch: [0][300/391]\tTime 0.538 (0.577)\tLoss 1.4172 (1.8218)\tPrec@1 53.125 (34.243)\tPrec@5 92.188 (84.710)\n",
      "Validation_time 22.634 Prec@1 50.840 Prec@5 93.750\n",
      "\t - Epoch: [1][0/391]\tTime 0.983 (0.983)\tLoss 1.3139 (1.3139)\tPrec@1 53.125 (53.125)\tPrec@5 96.875 (96.875)\n",
      "\t - Epoch: [1][100/391]\tTime 0.616 (0.579)\tLoss 1.2336 (1.3350)\tPrec@1 63.281 (51.841)\tPrec@5 92.188 (93.626)\n",
      "\t - Epoch: [1][200/391]\tTime 0.552 (0.578)\tLoss 1.1038 (1.2761)\tPrec@1 59.375 (54.019)\tPrec@5 96.875 (94.271)\n",
      "\t - Epoch: [1][300/391]\tTime 0.560 (0.576)\tLoss 1.1886 (1.2342)\tPrec@1 57.031 (55.513)\tPrec@5 93.750 (94.651)\n",
      "Validation_time 23.232 Prec@1 63.460 Prec@5 96.500\n",
      "##### Evaluation ends (Time : 3054.049)\n",
      "##### [gen_time: 3054.050s] 3 th generation is finished.\n",
      "3  \t8    \t[-6.60300000e+01  1.28832512e+09]\t[-5.83200000e+01  1.69092864e+09]\t3054.05   \t3054.05 \n",
      "##### 4 th generation starts\n",
      "##### Evaluation starts\n",
      "\t - Epoch: [0][0/391]\tTime 0.881 (0.881)\tLoss 6.9012 (6.9012)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.353 (0.374)\tLoss 1.8393 (2.2375)\tPrec@1 32.031 (22.146)\tPrec@5 84.375 (73.538)\n",
      "\t - Epoch: [0][200/391]\tTime 0.356 (0.375)\tLoss 1.5360 (1.9947)\tPrec@1 44.531 (28.743)\tPrec@5 89.062 (79.839)\n",
      "\t - Epoch: [0][300/391]\tTime 0.339 (0.375)\tLoss 1.3819 (1.8581)\tPrec@1 50.781 (32.999)\tPrec@5 96.094 (83.225)\n",
      "Validation_time 15.639 Prec@1 48.610 Prec@5 93.350\n",
      "\t - Epoch: [1][0/391]\tTime 0.745 (0.745)\tLoss 1.2740 (1.2740)\tPrec@1 53.125 (53.125)\tPrec@5 95.312 (95.312)\n",
      "\t - Epoch: [1][100/391]\tTime 0.356 (0.376)\tLoss 1.4098 (1.3393)\tPrec@1 47.656 (51.493)\tPrec@5 89.844 (93.533)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Epoch: [1][200/391]\tTime 0.357 (0.376)\tLoss 1.1565 (1.2734)\tPrec@1 57.812 (54.073)\tPrec@5 95.312 (94.240)\n",
      "\t - Epoch: [1][300/391]\tTime 0.421 (0.375)\tLoss 0.9392 (1.2226)\tPrec@1 63.281 (56.019)\tPrec@5 98.438 (94.778)\n",
      "Validation_time 15.633 Prec@1 63.940 Prec@5 96.660\n",
      "\t - Epoch: [0][0/391]\tTime 0.807 (0.807)\tLoss 6.8713 (6.8713)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      "\t - Epoch: [0][100/391]\tTime 0.674 (0.491)\tLoss 1.8301 (2.1393)\tPrec@1 32.812 (26.276)\tPrec@5 84.375 (77.955)\n",
      "\t - Epoch: [0][200/391]\tTime 0.449 (0.491)\tLoss 1.5040 (1.9215)\tPrec@1 39.062 (31.720)\tPrec@5 90.625 (82.964)\n",
      "\t - Epoch: [0][300/391]\tTime 0.461 (0.490)\tLoss 1.4602 (1.7983)\tPrec@1 50.000 (35.244)\tPrec@5 92.969 (85.450)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "4. Algorithms\n",
    " For the purpose of completeness we will develop the complete generational algorithm.\n",
    "\"\"\"\n",
    "\n",
    "POP_SIZE = 8    # population size\n",
    "NGEN = 10    # number of Generation\n",
    "CXPB = 0.5    # crossover probability \n",
    "MUTPB = 0.5    # mutation probability\n",
    "\n",
    "\n",
    "# log에 기록할 stats\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"min\", np.min, axis=0)\n",
    "stats.register(\"max\", np.max, axis=0)\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "logbook.header = \"gen\", \"evals\", \"min\", \"max\", \"evals_time\", \"gen_time\"\n",
    "\n",
    "# population 생성.  (toolbox.population은 creator.Individual n개를 담은 list를 반환. (=> population)\n",
    "print(\"Initialion starts ...\")\n",
    "pop = toolbox.population(n=POP_SIZE)\n",
    "\n",
    "# Evaluate the individuals with an invalid fitness\n",
    "invalid_ind = [ind for ind in pop if not ind.fitness.valid]\n",
    "fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)    # .evaluate는 tuple을 반환. 따라서 fitnesses는 튜플을 원소로 가지는 list\n",
    "for ind, fit in zip(invalid_ind, fitnesses):\n",
    "    ind.fitness.values = fit   # ind.fitness.values = (val_accuracy, flops) 튜플\n",
    "\n",
    "# This is just to assign the crowding distance to the individuals\n",
    "# no actual selection is done\n",
    "pop = toolbox.select(pop, len(pop))\n",
    "\n",
    "record = stats.compile(pop)\n",
    "logbook.record(gen=0, evals=len(invalid_ind), **record)\n",
    "print(logbook.stream)\n",
    "print(\"Initialization is finished.\\n\")\n",
    "\n",
    "# Begin the generational process\n",
    "for gen in range(1, NGEN):\n",
    "    print(\"#####\", gen, \"th generation starts\")\n",
    "    start_gen = time.time()\n",
    "    # Vary the population\n",
    "    offspring = tools.selTournamentDCD(pop, len(pop))\n",
    "    offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "\n",
    "    for ind1, ind2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() <= CXPB:\n",
    "            toolbox.mate(ind1, ind2)\n",
    "\n",
    "        toolbox.mutate(ind1, indpb=MUTPB)\n",
    "        toolbox.mutate(ind2, indpb=MUTPB)\n",
    "        del ind1.fitness.values, ind2.fitness.values\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    print(\"##### Evaluation starts\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "        \n",
    "    eval_time_for_one_generation = time.time() - start_time        \n",
    "    print(\"##### Evaluation ends (Time : %.3f)\" % eval_time_for_one_generation)\n",
    "    \n",
    "    # Select the next generation population\n",
    "    pop = toolbox.select(pop + offspring, POP_SIZE)\n",
    "    \n",
    "    gen_time = time.time() - start_gen\n",
    "    print('##### [gen_time: %.3fs]' % gen_time, gen, 'th generation is finished.')\n",
    "    \n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=gen, evals=len(invalid_ind), **record,\n",
    "                   evals_time=eval_time_for_one_generation, gen_time=gen_time)\n",
    "    \n",
    "    logging.info('Gen [%03d/%03d] -- evals: %03d, evals_time: %.4fs, gen_time: %.4fs' % (gen, NGEN, len(invalid_ind), eval_time_for_one_generation, gen_time))    \n",
    "    print(logbook.stream)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# logbook save 하기 - 매 generation 지날때마다 해당 파일에 덮어쓰도록.\n",
    "# save paths는 run_code 붙여서 logs 폴더에\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- 190813\n",
    "- POP_SIZE = 8, EPOCH = 2\n",
    "\n",
    "##### [gen_time: 3253.266s] 1 th generation is finished.\n",
    "1  \t8    \t[-6.49600000e+01  1.46135194e+09]\t[-5.61200000e+01  1.74673242e+09]\t3253.27   \t3253.27 \n",
    "\n",
    "##### [gen_time: 3276.617s] 2 th generation is finished.\n",
    "2  \t8    \t[-6.49600000e+01  1.38388634e+09]\t[-5.61200000e+01  1.74673242e+09]\t3276.62   \t3276.62 \n",
    "\n",
    "##### [gen_time: 3054.050s] 3 th generation is finished.\n",
    "3  \t8    \t[-6.60300000e+01  1.28832512e+09]\t[-5.83200000e+01  1.69092864e+09]\t3054.05   \t3054.05 \n",
    "\n",
    "- EPOCH = 10으로 늘리면, 대략 5배 -> POP_SIZE = 8 일때, 1 gen 당 15,000초 (=250분. 4시간 10분)\n",
    "\n",
    "=> 3th generation에서 끝남. why?\n",
    "\n",
    "+ log 쓰는 방법. log book 말고, 다른 파일에 write해서 save 될 수 있도록.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RWNN 코드 연습 (보관용)  -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_WS(Nodes, K, P):\n",
    "    return nx.random_graphs.connected_watts_strogatz_graph(Nodes, K, P, tries=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Node = collections.namedtuple('Node', ['id', 'inputs', 'type'])  # typename, field_names\n",
    "\n",
    "def get_graph_info(graph):\n",
    "    input_nodes = []\n",
    "    output_nodes = []\n",
    "    Nodes = []\n",
    "    for node in range(graph.number_of_nodes()):\n",
    "        # node i 에 대해        \n",
    "        tmp = list(graph.neighbors(node))\n",
    "        tmp.sort()    # 오름차순 정렬\n",
    "    \n",
    "        # node type 정의    \n",
    "        type = -1    # input node도, output node도 아닌. 그래프의 중간에 매개자처럼 있는 중간 node.\n",
    "        if node < tmp[0]:\n",
    "            input_nodes.append(node)\n",
    "            type = 0    # id 가장 작은 노드보다 작으면, 이건 외부에서 input을 받는 노드. 즉 input node.\n",
    "        if node > tmp[-1]:\n",
    "            output_nodes.append(node)\n",
    "            type = 1    # id 가장 큰 노드보다 크면, 이건 외부로 output 내보내는 노드. 즉 output node.\n",
    "        \n",
    "        # dag로 변환 (자신의 id보다 작은 노드들과의 연결만 남기기)\n",
    "        # [type] 0: input node, 1: output node, -1: input도 output도 아닌, 그래프 중간에 매개자처럼 있는 중간 node\n",
    "        Nodes.append(Node(node, [n for n in tmp if n < node], type))    # DAG(Directed Acyclic Graph)로 변환\n",
    "    return Nodes, input_nodes, output_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nodes = 32\n",
    "K = 4\n",
    "P = 0.75\n",
    "\n",
    "sample_graph = build_graph_WS(Nodes, K, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sample_graph.neighbors(0))   # 0번 노드의 neightbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nodes, input_nodes, output_nodes = get_graph_info(sample_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Nodes   # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Nodes))\n",
    "print(input_nodes)\n",
    "print(output_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Nodes\n",
    "import pickle\n",
    "\n",
    "with open('Nodes_1', 'wb') as fp:\n",
    "    pickle.dump(Nodes, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('Nodes_1', 'rb') as fp:\n",
    "    temp = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
